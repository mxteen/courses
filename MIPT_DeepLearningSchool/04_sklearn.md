# Семинар. Библиотека sklearn

* [Видео]()
* [Материалы занятия](https://drive.google.com/drive/folders/13Do1OBgB67XCPZx84ODnQt8bbc8Gh7MQ?usp=sharing): презентация, данные, Jupyter-notebook

**Перессказ** от YandexGPT

Семинар 1. Введение в машинное обучение.

00:06 Введение

* В этом видео рассказывается о семинаре, который посвящен разнообразным инструментам, используемым в машинном обучении.
* В начале семинара автор объясняет, что такое jupyter ноутбуки и Google Colab, а также предоставляет ссылки на дополнительные материалы для самостоятельного изучения.

02:04 Использование jupyter-ноутбуков

* Автор объясняет, как использовать jupyter-ноутбуки для обучения и исследования кода.
* Он также упоминает, что ноутбуки могут быть исполнены построчно, что позволяет контролировать процесс выполнения кода.

05:57 Использование Google-Colab

* Колаб - это сервер jupyter-ноутбуков, который позволяет пользователям запускать ноутбуки в браузере.
* Однако, для проведения сложных вычислений может потребоваться больше вычислительных ресурсов, которые могут быть недоступны на компьютере пользователя.

09:52 Pandas, Matplotlib и линейная алгебра

* Автор упоминает, что для успешного прохождения курса необходимо знание pandas, matplotlib и линейной алгебры.
* Он также подчеркивает, что эти знания не являются обязательными для прохождения курса, но могут быть полезны для самостоятельного изучения.

11:47 Семинар

* В семинаре основное внимание уделяется использованию библиотеки скаляр для работы с моделями и трансформерами, а также важности предварительной обработки данных перед началом работы над задачей.
* Автор также подчеркивает, что перед началом работы над задачей необходимо изучить данные и понять, насколько она может быть решена простыми методами.

14:43 Введение

* Трансформеры - это алгоритмы машинного обучения, которые могут обучаться на основе данных, которые уже есть.
* Они используют два основных метода: .
* feed и .
* transform.
* В видео используется набор данных о приложениях, которые продаются в AppStore.

16:37 Обработка данных

* Импортируются необходимые библиотеки: pandas, pandas и matplotlib.
* read_csv используется для чтения данных из файла с разделителями-запятыми.
* head используется для вывода первых пяти строк данных.

22:29 Визуализация данных

* Разделение данных на числовые и категориальные признаки.
* Обрезка последнего символа в колонке "контент рейтинг" для преобразования в числовое значение.
* Проверка на наличие пропущенных значений в данных.
* Агрегирование данных с помощью функции .
* min.

27:22 Распределение данных

* Использование pandas.
* value_counts для просмотра распределения значений в категориальных колонках.
* Удаление колонки "контент рейтинг", если она содержит только одно значение.
* Визуализация данных с помощью функции pandas .
* hist.

30:16 Корреляция и обработка данных

* В видео обсуждается важность корреляции между признаками и целевой переменной в данных.
* Если корреляция между признаками и целевой переменной высокая, это может указывать на то, что один из признаков может быть использован в качестве предиктора для предсказания значения целевой переменной.
* Обсуждается также важность очистки данных перед использованием их в машинном обучении.
* Очистка данных включает в себя удаление ошибочных записей, исправление ошибок и создание новых признаков.

39:01 Создание новых признаков

* Создание новых признаков может помочь алгоритму машинного обучения лучше восстановить сложные зависимости в данных.
* В видео приводится пример создания новых признаков с использованием по парных произведений исходных признаков.
* Также обсуждается использование категориальных признаков и их преобразование в числовые значения с помощью one-hot encoding.
* Этот метод позволяет закодировать категориальный признак в виде вектора из единиц и нулей, где единица соответствует значению категориальной переменной.

44:52 Обработка данных

* В видео автор объясняет, как обрабатывать данные в Python, используя различные функции и методы.
* Он также обсуждает, как использовать функции для преобразования данных, такие как стандартизация и масштабирование признаков.
* Автор объясняет, что важно использовать функции для преобразования данных, чтобы избежать утечки информации между обучающей и тестовой выборками.

53:39 Разделение данных

* Автор объясняет, как использовать функцию train_test_split из sklearn для разделения данных на обучающую и тестовую выборки.
* Он подчеркивает, что все передаваемые аргументы должны быть похожи на списки, такие как матрицы или векторы.

57:27 Обучение модели

* Автор объясняет, что метрика - это функция, которая оценивает качество модели, но не обязательно должна быть связана с функцией потерь.
* Он приводит примеры метрик, таких как точность и R-квадрат, и объясняет, как они используются для оценки качества модели.

01:00:23 Метрики и кросс-валидация

* Метрики используются для сравнения алгоритмов и оптимизации.
* Кросс-валидация - это метод разделения данных на части для оценки качества модели.

01:06:16 Линейная регрессия и кросс-валидация

* Кросс-валидация разделяет данные на 5 частей и вычисляет метрики для каждой части.
* Итоговые метрики усредняются для сравнения моделей.

01:10:08 Использование GridSearchCV для оптимизации гиперпараметров

* GridSearchCV - это класс, который позволяет автоматически подбирать лучшие параметры для модели.
* Он использует кросс-валидацию для определения оптимальных параметров и обучает модель с этими параметрами.

