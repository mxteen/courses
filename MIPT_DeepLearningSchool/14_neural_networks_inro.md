# Введение в нейронные сети

* [История развития Deep Learning](https://www.youtube.com/watch?v=ZfXpX8tMg-w)
*  Механизм обратного распространения ошибки
* 

## Введение в нейронные сети. Часть 1. История развития Deep Learning

Видео: https://www.youtube.com/watch?v=ZfXpX8tMg-w

**Перессказ от YandexGPT**

00:06 Введение в искусственные нейронные сети

* Родослав Нечев, автор курсов по машинному обучению, представляет лекцию о искусственных нейронных сетях и глубоком обучении.
* Лекция - историческая справка.

04:15 Историческая справка

* Первая точка на временной шкале истории нейронных сетей относится к сороковым годам (1940).
* В 1943 году учитель и ученик, Маккало и Пиц, представили математическую модель нейронных сетей.
* В 1958 году Фрэнк Розенблатт представил перцептрон, который стал основой для современных нейронных сетей.

06:01 Механизм обратного распространения ошибки

* Обратный процесс ошибки или "back propogation" является краеугольным камнем в обучении нейронных сетей.
* Понимание этого процесса важно для понимания того, как нейронные сети учатся и где их можно применять.

08:10 Функции активации

* В лекции будут рассмотрены различные функции активации, которые используются в нейронных сетях для определения того, как нейроны реагируют на входные данные.
* В конце лекции будет представлен обзор интересных нейронных сетей и игровая площадка для построения нейронных сетей в браузере без кода.

09:19 Перцептрон и его применение

* Перцептрон - математическая модель нейрона, на основе которой была построена система машинного зрения в 60-х годах.
* Система обучалась различать цвета, используя собственный опыт и метод проб и ошибок.

10:19 Критика и смерть Фрэнка Розенблата

* После публикации работы Фрэнка Розенблата, вышла критика, утверждающая, что перцептрон не способен перевернуть мир.
* Фрэнк Розенблат не смог ответить на критику по объективным причинам. Это посспособствовало временной утрате интереса к нейронным сетям.

11:12 Проблема исключающего или и ее решение

* Проблема линейной неразделимости точек, которые можно разделить только с использованием новых признаков.
* Добавление второго слоя нейронной сети позволяет решить проблему с использованием линейных моделей.

13:16 Появление обратного распространения ошибки

* Метод обратного распространения ошибки, предложенный одновременно в двух лагерях, определяет дальнейшее развитие нейронных сетей.
* Появление новых моделей и эйфория от их использования, но затем интерес к ним угасает на 10 лет.

15:05 Развитие нейронных сетей в 2000-х годах

* Нейронные сети продолжают развиваться, появляются новые открытия и идеи, но в академической среде.
* В 2011-2012 годах нейронные сети заявляют о себе на соревновании ImageNet, переворачивая ситуацию в свою пользу.

16:41 История нейронных сетей

* Видео начинается с обзора истории нейронных сетей, начиная с простой сети "AlexNet", которая победила на соревнованиях по классификации изображений.
* "AlexNet" имеет структуру, похожую на "Lent" Яна Ликуна, но с более современными подходами.
* Появление "AlexNet" привлекло внимание к нейронным сетям, но интерес к ним возрос только после накопления достаточного объема данных для обучения.

19:31 Современные достижения

* В настоящее время нейронные сети используются для решения различных задач, включая распознавание объектов, семантическую сегментацию, генерацию подписей к изображениям, смену стиля фотографий, обработку звуков и генерацию изображений.
* Генеративные состязательные сети (GAN) позволяют генерировать изображения и звуки, которые выглядят и звучат реалистично.

22:32 Основы и последние достижения

* В последние годы появилось множество моделей для обработки естественного языка, включая трансформер-модели и модели с большим количеством параметров.
* В видео также упоминается "Bert", который является стандартом де-факто в обработке естественного языка, и GPT2, которая имеет 1,5 миллиарда параметров.
* Область глубокого обучения продолжает развиваться, и в видео обсуждаются различные подходы и модели, которые используются в этой области.

