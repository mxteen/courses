{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Корректность проверена на Python 3.6:**\n",
    "+ gensim 3.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример использования библиотеки gensim для тематического моделирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такая полезная теорема Байеса! :)\n",
    "\n",
    "![comic1](http://imgs.xkcd.com/comics/seashell.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `gensim` реализована модель LDA (Latent Dirichlet Allocation), обучение которой основано на эволюционном байесовском выводе. LDA, действительно, очень популярны, и часто их используют просто как «чёрный ящик», подают матрице частоты слов и получают на выходе построенные матрицы.\n",
    "\n",
    "Мы импортируем компоненты corpora и models из модуля gensim. Первый поможет нам импортировать данные, а второй — построить непосредственно модель. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mi.terentev\\.conda\\envs\\Orange\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы возьмём dataset, состоящий из текстовых описаний к комиксам [xkcd](https://xkcd.com/).\n",
    "\n",
    "Данные у нас представлены в формате UCI Bag of Words. Это популярный формат, который позволяет максимально сжато представить разреженную матрицу частот слов. \n",
    "\n",
    "Итак, давайте импортируем эти файлы в нашу модель. Для этого мы создадим объект класса UciCorpus и укажем путь к двум нашим файлам. Также gensim требует, чтобы мы в отдельную переменную обязательно сохранили словарь. Это можно сделать с помощью метода create_dictionary у объекта data, который мы получили в первой строке. Теперь мы готовы к обучению модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем данные в формте UCI Bag of Words\n",
    "data = corpora.UciCorpus(\"docword.xkcd.txt\", \"vocab.xkcd.txt\")\n",
    "dictionary = data.create_dictionary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый параметр — это corpus, у нас это, он хранится в переменной data, мы её и указываем. Второй параметр, который, конечно, необязателен, но крайне желательно его указать, это id2word. Это, собственно, отображение индексов слов непосредственно в слова. У нас это как раз тот dictionary, который мы создали во второй строке предыдущей ячейки. Далее идут некоторые параметры, которые влияют на обучение модели. Если у вас коллекция небольшая, как в нашем случае, то можно сделать много проходов по коллекции, и тогда модель получится наиболее адекватной. Тогда нужно указать параметр passes большим, например 20. Если же у вас коллекция действительно большая, например, как «википедия», то делать по ней двадцать проходов будет очень долго. Тогда можно указывать один или два прохода, но нужно обязательно подобрать аккуратно другие параметры, влияющие на сходимость алгоритмов. Особенно это параметры decay и offset, но об этом мы не будем подробно говорить в нашей демонстрации. Кроме того, полезно указывать параметр distributed, например, в true, тогда вы сможете обучать модель сразу в нескольких параллельных процессах. Ещё два важных параметра модели — это alpha и eta. Они создают априорные параметры распределения Дирихле, точнее, параметры априорного распределения Дирихле для моделей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "# обучение модели\n",
    "%time ldamodel = models.ldamodel.LdaModel(data, id2word=dictionary, num_topics=5, passes=20, alpha=1.25, eta=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "ldamodel.save(\"ldamodel_xkcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка модели\n",
    "ldamodel = models.ldamodel.LdaModel.load(\"ldamodel_xkcd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что в первых двух темах много имён, и, честно сказать, не очень понятно, о чём эти темы. Третья тема, она посвящена комиксам в таком стиле: там любят рисовать график, и этот график как-то связан со временем, и идёт какой-то сопровождающий текст. Потом говорят слова: «рисунок», «метка», «линия», «год», «время». Третья тема — это тема для комиксов из серии, когда на нём есть мужчина, женщина, то есть два человека, и они что-то обсуждают. А четвёртая тема весьма специфична. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 : 0.001*\"b'day'\" + 0.001*\"b'planet'\" + 0.001*\"b'dot'\" + 0.001*\"b'beef'\" + 0.001*\"b'human'\" + 0.001*\"b'gliese'\" + 0.001*\"b'scientist'\" + 0.001*\"b'degree'\" + 0.001*\"b'easy'\" + 0.001*\"b'leopard'\"\n",
      "Topic 1 : 0.006*\"b'woman'\" + 0.005*\"b'man'\" + 0.002*\"b'exhibit'\" + 0.002*\"b'female'\" + 0.002*\"b'goggles'\" + 0.002*\"b'child'\" + 0.001*\"b'found'\" + 0.001*\"b'male'\" + 0.001*\"b'link'\" + 0.001*\"b'text'\"\n",
      "Topic 2 : 0.022*\"b'man'\" + 0.012*\"b'text'\" + 0.012*\"b'person'\" + 0.011*\"b'title'\" + 0.009*\"b'guy'\" + 0.008*\"b'woman'\" + 0.006*\"b'one'\" + 0.006*\"b'girl'\" + 0.005*\"b'just'\" + 0.005*\"b'hat'\"\n",
      "Topic 3 : 0.001*\"b'nathan'\" + 0.001*\"b'title'\" + 0.001*\"b'text'\" + 0.001*\"b'roberts'\" + 0.001*\"b'turtle'\" + 0.001*\"b'cop'\" + 0.001*\"b'elaine'\" + 0.001*\"b'hatboy'\" + 0.001*\"b'cat'\" + 0.001*\"b'human'\"\n",
      "Topic 4 : 0.004*\"b'line'\" + 0.003*\"b'labeled'\" + 0.002*\"b'wait'\" + 0.002*\"b'map'\" + 0.002*\"b'one'\" + 0.002*\"b'boy'\" + 0.002*\"b'graph'\" + 0.001*\"b'within'\" + 0.001*\"b'peter'\" + 0.001*\"b'island'\"\n"
     ]
    }
   ],
   "source": [
    "# выводим топы слов\n",
    "for t, top_words in ldamodel.print_topics(num_topics=10, num_words=10):\n",
    "    print(\"Topic\", t, \":\", top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351.2259898670064\n"
     ]
    }
   ],
   "source": [
    "# Вычисляем логарифм перплексии и немного преобразуем, чтобы привести к общепринятому виду\n",
    "perplexity = ldamodel.log_perplexity(list(data))\n",
    "print(2**(-perplexity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "давайте посчитаем величину перплексии на нашей модели. Перплексия — это очень распространённая мера качества тематических моделей, и особенное значение она имеет в контексте байесовских моделей. В первую очередь, потому что она описывает, насколько хорошо ваше распределение, описывает ваши исходные данные. И интерпретировать его можно так: чем меньше значение перплексии, тем лучше. С другой стороны, у перплексии нет максимального значения. То есть непонятно, если нам вручили число, непонятно, что оно означает. И ещё очень важно, что величина перплексии зависит, во-первых, от данных, а во-вторых, от количества тем. Поэтому, во-первых, нельзя сравнивать перплексию модели, построенных на разных данных, а во-вторых, нельзя по перплексии выбирать количество тем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351.22599973675716"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perp = ldamodel.bound(data)\n",
    "2**(-perp/float(87409))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте также обсудим ещё две важные функции, которые предоставляет gensim. Во-первых, это функция update, которая позволяет дообучить модель на новых данных. То есть, если, например, вы бы считали ещё один другой corpus, например, из новых комиксов, в переменную data2 и указали бы её как первый аргумент функции update и также указали бы, сколько сделать проходов по коллекции, чтобы дообучить модель, то gensim обновит все параметры. Ещё одна важная функция — это get_document_topics. Он позволяет для каждого документа найти распределение над множеством тем. Давайте получим распределение для другого документа и увидим, что в нём наибольшую роль играет третья тема."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a67d52d954fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Добавление в модель новых документов, содержащихся в новом корупсе data2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mldamodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data2' is not defined"
     ]
    }
   ],
   "source": [
    "# Добавление в модель новых документов, содержащихся в новом корупсе data2\n",
    "ldamodel.update(data2, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.055764973),\n",
       " (1, 0.056286175),\n",
       " (2, 0.056032903),\n",
       " (3, 0.05806509),\n",
       " (4, 0.77385086)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получение распределения тем для конкретного документа\n",
    "doc = list(data)[0]\n",
    "ldamodel.get_document_topics(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти люди не знают про тематические модели:\n",
    "\n",
    "![comic2](http://imgs.xkcd.com/comics/the_problem_with_wikipedia.png) | ![comic3](http://imgs.xkcd.com/comics/mystery_news.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
