{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Sklearn\" data-toc-modified-id=\"Sklearn-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Sklearn</a></span><ul class=\"toc-item\"><li><span><a href=\"#sklearn.grid_search\" data-toc-modified-id=\"sklearn.grid_search-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>sklearn.grid_search</a></span><ul class=\"toc-item\"><li><span><a href=\"#Генерация-датасета\" data-toc-modified-id=\"Генерация-датасета-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Генерация датасета</a></span></li><li><span><a href=\"#Задание-модели\" data-toc-modified-id=\"Задание-модели-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Задание модели</a></span></li><li><span><a href=\"#Генерация-сетки\" data-toc-modified-id=\"Генерация-сетки-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Генерация сетки</a></span></li><li><span><a href=\"#Подбор-параметров-и-оценка-качества\" data-toc-modified-id=\"Подбор-параметров-и-оценка-качества-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Подбор параметров и оценка качества</a></span><ul class=\"toc-item\"><li><span><a href=\"#Grid-search\" data-toc-modified-id=\"Grid-search-1.1.4.1\"><span class=\"toc-item-num\">1.1.4.1&nbsp;&nbsp;</span>Grid search</a></span></li><li><span><a href=\"#Randomized-grid-search\" data-toc-modified-id=\"Randomized-grid-search-1.1.4.2\"><span class=\"toc-item-num\">1.1.4.2&nbsp;&nbsp;</span>Randomized grid search</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Корректность проверена на Python 3.6:**\n",
    "+ pandas 0.23.4\n",
    "+ numpy 1.15.4\n",
    "+ sklearn 0.20.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "каким образом можно подбирать параметры, оптимальные для решаемой задачи? В этом видео мы будем рассматривать модуль grid_search в библиотеке sklearn и научимся подбирать параметры модели по сетке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "документация: http://scikit-learn.org/stable/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, datasets, linear_model, metrics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.train_test_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = model_selection.train_test_split(iris.data, iris.target, \n",
    "                                                                                     test_size = 0.3,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "давайте выберем модель — пусть это будет SGD-классификатор — и создадим объект с параметрами по умолчанию. Теперь можно подбирать параметры. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.SGDClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = linear_model.SGDClassifier(random_state = 0, tol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация сетки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'average', 'class_weight', 'early_stopping', 'epsilon', 'eta0', 'fit_intercept', 'l1_ratio', 'learning_rate', 'loss', 'max_iter', 'n_iter_no_change', 'n_jobs', 'penalty', 'power_t', 'random_state', 'shuffle', 'tol', 'validation_fraction', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Можно выбрать вид функции потерь, будем рассматривать hinge, log, squared_hinge и squared_loss. \n",
    "2. Также давайте выберем вид регуляризации — выберем между l1 и l2.\n",
    "3. Также можем подобрать количество итераций — давайте подбирать от 5 до 10, по умолчанию у нас 5 итераций. \n",
    "5. И выберем коэффициент alpha — это множитель перед регуляризацией. По умолчанию у нас доступно значение 0,0001. Ну, вот давайте создадим отрезок от 0,0001 до 0,001, бросим на него равномерно пять точек и будем использовать их в качестве весов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_grid = {\n",
    "    'loss' : ['hinge', 'log', 'squared_hinge', 'squared_loss'],\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'max_iter' : np.arange(5,10),\n",
    "    'alpha' : np.linspace(0.0001, 0.001, num = 5),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, давайте создадим стратегию кросс-валидации, с помощью которой мы будем оценивать качество. В данном случае я использую `StratifiedShuffleSplit`, будем делать 10 разбиений, и в тестовую выборку будет идти 20 % данных. И теперь можно перейти непосредственно к подбору параметров. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.StratifiedShuffleSplit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = model_selection.StratifiedShuffleSplit(n_splits=10, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров и оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search\n",
    "\n",
    " В данном случае в **качестве сетки мы будем использовать словарь `parameters_grid`, у которого ключ — это название параметра, который мы подбираем, а в качестве значения идет набор значений, которые мы хотим проверить**. Таким образом, если мы построим декартово произведение на этих параметрах, то мы получим точки со всеми возможными наборами параметров. Собственно, это нам и хочется получить. **Мы хотим в каждой из этих точек измерить качество классификации, далее сравнить, посмотреть, где качество максимальное, и сказать, что вот это есть оптимальные параметры**.\n",
    " \n",
    " Для начала давайте **создадим объект grid_search, с помощью которого мы будем это делать**. Данному **объекту нужно обязательно передать модель, которую мы хотим оптимизировать** — в данном случае наш SGD-классификатор. Также нужно **передать сетку с параметрами**, по которой мы будем бегать. Нужно **указать метрику, которую мы будем проверять**, и **стратегию кросс-валидации**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.GridSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = model_selection.GridSearchCV(estimator=classifier,\n",
    "                                       param_grid=parameters_grid,\n",
    "                                       scoring = 'accuracy',\n",
    "                                       cv = cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.84 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=0.2,\n",
       "            train_size=None),\n",
       "             estimator=SGDClassifier(random_state=0),\n",
       "             param_grid={'alpha': array([0.0001  , 0.000325, 0.00055 , 0.000775, 0.001   ]),\n",
       "                         'loss': ['hinge', 'log', 'squared_hinge',\n",
       "                                  'squared_loss'],\n",
       "                         'max_iter': array([5, 6, 7, 8, 9]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**нас интересует самый лучший классификатор — его можно найти с помощью команды `best_estimator`**. Видим, что здесь нам возвращается модель с лучшими параметрами. Отдельно можем попросить best_score, или оценку на лучшем наборе параметров, и, собственно, вывести лучшие наборы параметров в виде вот просто словаря параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0007750000000000001, max_iter=9, penalty='l1',\n",
       "              random_state=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9047619047619048\n",
      "{'alpha': 0.0007750000000000001, 'loss': 'hinge', 'max_iter': 9, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_cv.best_score_)\n",
    "print(grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0021975 , 0.00159557, 0.00159581, 0.00159497, 0.00159562,\n",
       "        0.00159585, 0.00159566, 0.00169556, 0.00159569, 0.00159574,\n",
       "        0.00149601, 0.00169544, 0.00159574, 0.00179517, 0.00170028,\n",
       "        0.00159569, 0.00179515, 0.00159571, 0.0017952 , 0.00159643,\n",
       "        0.00169663, 0.00149598, 0.00159574, 0.00149605, 0.00169549,\n",
       "        0.00169563, 0.00179527, 0.00159569, 0.00169547, 0.00179493,\n",
       "        0.00179517, 0.00159569, 0.00149593, 0.00149603, 0.00169532,\n",
       "        0.00159578, 0.00149591, 0.00159583, 0.00159566, 0.00149593,\n",
       "        0.00159564, 0.00159559, 0.00169537, 0.00159578, 0.00179491,\n",
       "        0.00159557, 0.00169539, 0.00149369, 0.00159497, 0.00149634,\n",
       "        0.00169351, 0.00159478, 0.00210075, 0.00199702, 0.0018873 ,\n",
       "        0.00159569, 0.00169556, 0.00159581, 0.00169959, 0.00179608,\n",
       "        0.0015964 , 0.00169981, 0.00169859, 0.00168855, 0.0015959 ,\n",
       "        0.00169561, 0.00169148, 0.00208964, 0.00170665, 0.00159707,\n",
       "        0.00169663, 0.00170348, 0.00160198, 0.0015861 , 0.00199459,\n",
       "        0.00189629, 0.00149715, 0.00169091, 0.00188847, 0.00179496,\n",
       "        0.00149534, 0.00139627, 0.00159755, 0.00159562, 0.00159366,\n",
       "        0.00179336, 0.00159569, 0.00169532, 0.00169549, 0.00159564,\n",
       "        0.00179486, 0.00169556, 0.00159848, 0.00179513, 0.00169551,\n",
       "        0.00159583, 0.00169659, 0.0015955 , 0.00159578, 0.00159507,\n",
       "        0.0015959 , 0.00159156, 0.00159626, 0.00159457, 0.00169179,\n",
       "        0.00159101, 0.00169818, 0.00150113, 0.00179524, 0.00159588,\n",
       "        0.00169225, 0.00149598, 0.00169544, 0.00159574, 0.00149598,\n",
       "        0.00149596, 0.00199783, 0.00159593, 0.00169535, 0.0013963 ,\n",
       "        0.00149605, 0.00159574, 0.00159564, 0.00149596, 0.00159571,\n",
       "        0.00149598, 0.00149593, 0.00169549, 0.00139627, 0.00149586,\n",
       "        0.00179517, 0.00159991, 0.00149469, 0.00159559, 0.00159578,\n",
       "        0.00169547, 0.00169542, 0.00179522, 0.00159581, 0.00159569,\n",
       "        0.00149612, 0.00149601, 0.00159574, 0.00139616, 0.00169547,\n",
       "        0.00159574, 0.00159564, 0.00139623, 0.00169547, 0.00229399,\n",
       "        0.00189431, 0.00159588, 0.00189452, 0.00179515, 0.00159576,\n",
       "        0.00169497, 0.00189362, 0.00158894, 0.00180266, 0.00189812,\n",
       "        0.00178874, 0.00259645, 0.00229337, 0.00209458, 0.00229344,\n",
       "        0.00219538, 0.00169215, 0.00159829, 0.00170276, 0.00189176,\n",
       "        0.00209439, 0.00189483, 0.00209446, 0.00568738, 0.00209415,\n",
       "        0.00210884, 0.00239367, 0.00189509, 0.00209439, 0.00189481,\n",
       "        0.00199482, 0.00149689, 0.00159683, 0.00159583, 0.0014987 ,\n",
       "        0.00170019, 0.00179379, 0.00189373, 0.00169544, 0.00149596,\n",
       "        0.00149591, 0.00169551, 0.00169528, 0.00159578, 0.00159569,\n",
       "        0.00169542, 0.00159576, 0.00159566, 0.00159564, 0.00159569]),\n",
       " 'std_fit_time': array([1.40580861e-03, 4.88538216e-04, 4.88577729e-04, 4.87708381e-04,\n",
       "        4.88567958e-04, 4.88616647e-04, 4.88606872e-04, 4.57012261e-04,\n",
       "        4.88626309e-04, 4.88567943e-04, 4.98795589e-04, 4.57090200e-04,\n",
       "        4.88470621e-04, 3.98933908e-04, 4.60471033e-04, 4.88626355e-04,\n",
       "        3.98981609e-04, 4.88694448e-04, 3.98945848e-04, 4.88942384e-04,\n",
       "        4.57727309e-04, 4.98724052e-04, 4.88567955e-04, 4.98604809e-04,\n",
       "        4.57017375e-04, 4.57476064e-04, 3.98981699e-04, 4.88529114e-04,\n",
       "        4.57105860e-04, 3.98874343e-04, 3.98874372e-04, 4.88626379e-04,\n",
       "        4.98676339e-04, 4.98724048e-04, 4.57064236e-04, 4.88509555e-04,\n",
       "        4.98795669e-04, 4.88694643e-04, 4.88558357e-04, 4.98628701e-04,\n",
       "        4.88636050e-04, 4.88500320e-04, 4.56835412e-04, 4.88850315e-04,\n",
       "        5.98184491e-04, 4.88528978e-04, 4.57059025e-04, 4.97204452e-04,\n",
       "        4.89272089e-04, 4.97894405e-04, 4.59059981e-04, 4.85126014e-04,\n",
       "        5.41657962e-04, 7.74739912e-04, 1.12417769e-03, 4.88528975e-04,\n",
       "        4.56908118e-04, 4.88626323e-04, 4.59694642e-04, 4.05340054e-04,\n",
       "        4.86105768e-04, 4.60649785e-04, 4.59692230e-04, 4.60442291e-04,\n",
       "        4.88801769e-04, 4.57303609e-04, 4.62240321e-04, 7.03776247e-04,\n",
       "        4.50013963e-04, 4.82330416e-04, 4.52930280e-04, 4.61945413e-04,\n",
       "        4.71702248e-04, 4.88793874e-04, 8.88569124e-07, 3.00068554e-04,\n",
       "        4.97668711e-04, 4.61749218e-04, 1.12227498e-03, 3.99841509e-04,\n",
       "        4.97677931e-04, 4.88699540e-04, 4.88597322e-04, 4.87120983e-04,\n",
       "        4.85219615e-04, 3.97656853e-04, 4.88578028e-04, 4.57324573e-04,\n",
       "        4.57069499e-04, 4.88684756e-04, 3.98660102e-04, 4.57012460e-04,\n",
       "        4.85176574e-04, 3.98969697e-04, 4.57033072e-04, 4.88354391e-04,\n",
       "        4.58997551e-04, 4.89363725e-04, 4.88250199e-04, 4.89195614e-04,\n",
       "        4.85808510e-04, 4.93813770e-04, 4.88905824e-04, 4.94837786e-04,\n",
       "        4.54343589e-04, 4.84767437e-04, 4.60554374e-04, 4.96786252e-04,\n",
       "        3.99387910e-04, 4.87956474e-04, 4.54993194e-04, 4.98676316e-04,\n",
       "        4.57038290e-04, 4.88713937e-04, 4.98724007e-04, 4.98747873e-04,\n",
       "        1.10113971e-03, 4.88334516e-04, 4.56871910e-04, 4.88519276e-04,\n",
       "        4.98652472e-04, 4.88519261e-04, 4.88636085e-04, 4.98700208e-04,\n",
       "        4.88548460e-04, 4.98676327e-04, 4.98628678e-04, 4.57069387e-04,\n",
       "        4.88782105e-04, 4.98557187e-04, 3.99053367e-04, 4.92535777e-04,\n",
       "        4.98120638e-04, 4.88548469e-04, 4.88606962e-04, 4.57001788e-04,\n",
       "        4.57126632e-04, 3.99017380e-04, 4.88529013e-04, 4.88626344e-04,\n",
       "        4.98628947e-04, 4.98557125e-04, 4.88519250e-04, 4.88587401e-04,\n",
       "        4.57105810e-04, 4.88519273e-04, 4.88636097e-04, 4.88431680e-04,\n",
       "        4.56949768e-04, 1.34219052e-03, 6.96743876e-04, 4.88684895e-04,\n",
       "        2.99072513e-04, 5.98542159e-04, 4.88637612e-04, 4.56362567e-04,\n",
       "        2.99238117e-04, 4.90512644e-04, 6.01709249e-04, 7.03370813e-04,\n",
       "        5.96817655e-04, 6.63405975e-04, 6.38267087e-04, 5.37286888e-04,\n",
       "        4.57049538e-04, 8.71230263e-04, 4.55250949e-04, 4.90121615e-04,\n",
       "        4.48197550e-04, 2.98640055e-04, 5.37057716e-04, 2.99334735e-04,\n",
       "        5.37087791e-04, 1.17579342e-02, 2.99734813e-04, 7.37424899e-04,\n",
       "        4.88704257e-04, 2.99104754e-04, 2.98778935e-04, 2.99326891e-04,\n",
       "        4.46972111e-04, 4.98636635e-04, 4.89415148e-04, 4.88130890e-04,\n",
       "        5.03244808e-04, 4.60636239e-04, 3.98492046e-04, 2.98904745e-04,\n",
       "        4.57038165e-04, 4.98700162e-04, 4.98747974e-04, 4.57085082e-04,\n",
       "        4.57189098e-04, 4.88704188e-04, 4.88577668e-04, 4.57126594e-04,\n",
       "        4.88490071e-04, 4.88606884e-04, 4.88733433e-04, 4.88577691e-04]),\n",
       " 'mean_score_time': array([1.69181824e-03, 2.99310684e-04, 1.99460983e-04, 2.00319290e-04,\n",
       "        2.99286842e-04, 2.99215317e-04, 1.99460983e-04, 2.99239159e-04,\n",
       "        1.99437141e-04, 1.99437141e-04, 2.99191475e-04, 2.99215317e-04,\n",
       "        9.97066498e-05, 1.99460983e-04, 1.99413300e-04, 1.99437141e-04,\n",
       "        0.00000000e+00, 2.99191475e-04, 1.99437141e-04, 3.98373604e-04,\n",
       "        2.98118591e-04, 3.98969650e-04, 2.99167633e-04, 2.99191475e-04,\n",
       "        1.99437141e-04, 1.99460983e-04, 9.97066498e-05, 3.99041176e-04,\n",
       "        1.99484825e-04, 0.00000000e+00, 9.97543335e-05, 1.99460983e-04,\n",
       "        1.99460983e-04, 2.99215317e-04, 1.99484825e-04, 1.99460983e-04,\n",
       "        2.99215317e-04, 1.99460983e-04, 1.99532509e-04, 9.96589661e-05,\n",
       "        1.99532509e-04, 1.99604034e-04, 1.99556351e-04, 1.99460983e-04,\n",
       "        1.99437141e-04, 1.99532509e-04, 9.98020172e-05, 3.04174423e-04,\n",
       "        9.97543335e-05, 2.99334526e-04, 1.00040436e-04, 1.00183487e-04,\n",
       "        2.99477577e-04, 2.98690796e-04, 2.99167633e-04, 1.99508667e-04,\n",
       "        2.99143791e-04, 1.99460983e-04, 1.99460983e-04, 0.00000000e+00,\n",
       "        2.99572945e-04, 1.92785263e-04, 2.93517113e-04, 2.02965736e-04,\n",
       "        3.98898125e-04, 1.99413300e-04, 1.99508667e-04, 1.99007988e-04,\n",
       "        2.03919411e-04, 1.98745728e-04, 1.92713737e-04, 2.95877457e-04,\n",
       "        3.90887260e-04, 5.02133369e-04, 0.00000000e+00, 1.00636482e-04,\n",
       "        4.97817993e-04, 4.00972366e-04, 2.99167633e-04, 1.99460983e-04,\n",
       "        2.00271606e-04, 3.99947166e-04, 1.98578835e-04, 1.99794769e-04,\n",
       "        2.98523903e-04, 1.99246407e-04, 1.99484825e-04, 9.97066498e-05,\n",
       "        2.99239159e-04, 2.99406052e-04, 1.99484825e-04, 9.97781754e-05,\n",
       "        2.99263000e-04, 1.99508667e-04, 1.99508667e-04, 3.99255753e-04,\n",
       "        1.99317932e-04, 2.96211243e-04, 2.99382210e-04, 2.99453735e-04,\n",
       "        1.99413300e-04, 2.02369690e-04, 1.99556351e-04, 2.99715996e-04,\n",
       "        2.99477577e-04, 3.02386284e-04, 1.00469589e-04, 2.98905373e-04,\n",
       "        1.99341774e-04, 9.96589661e-05, 1.99508667e-04, 2.99239159e-04,\n",
       "        9.97543335e-05, 9.97304916e-05, 2.99191475e-04, 2.99167633e-04,\n",
       "        9.97066498e-05, 1.99341774e-04, 2.99096107e-04, 1.99437141e-04,\n",
       "        1.99460983e-04, 9.97066498e-05, 1.99484825e-04, 1.99484825e-04,\n",
       "        1.99508667e-04, 1.99460983e-04, 1.99484825e-04, 1.99460983e-04,\n",
       "        3.99017334e-04, 2.99215317e-04, 0.00000000e+00, 1.99103355e-04,\n",
       "        2.99263000e-04, 1.99556351e-04, 1.99437141e-04, 1.99484825e-04,\n",
       "        2.99239159e-04, 9.97304916e-05, 2.99167633e-04, 1.99437141e-04,\n",
       "        3.98898125e-04, 1.99413300e-04, 1.99460983e-04, 2.99263000e-04,\n",
       "        1.99460983e-04, 9.97304916e-05, 1.99484825e-04, 1.99460983e-04,\n",
       "        1.99460983e-04, 3.95560265e-04, 1.99437141e-04, 2.99191475e-04,\n",
       "        9.98020172e-05, 1.99460983e-04, 3.99041176e-04, 2.98976898e-04,\n",
       "        2.97212601e-04, 4.02021408e-04, 3.02624702e-04, 1.99294090e-04,\n",
       "        3.99160385e-04, 4.98509407e-04, 1.99723244e-04, 1.99460983e-04,\n",
       "        3.99160385e-04, 3.98993492e-04, 3.02362442e-04, 3.99422646e-04,\n",
       "        4.94670868e-04, 2.99239159e-04, 1.99508667e-04, 3.99088860e-04,\n",
       "        3.99088860e-04, 1.99460983e-04, 1.99437141e-04, 2.99072266e-04,\n",
       "        1.99413300e-04, 9.97304916e-05, 3.98945808e-04, 1.99556351e-04,\n",
       "        9.95635986e-05, 2.02798843e-04, 2.98976898e-04, 1.99222565e-04,\n",
       "        2.95424461e-04, 1.97720528e-04, 9.97543335e-05, 2.99072266e-04,\n",
       "        1.99460983e-04, 1.99460983e-04, 2.99191475e-04, 1.99437141e-04,\n",
       "        9.97304916e-05, 1.99437141e-04, 4.70685959e-04, 9.97543335e-05,\n",
       "        3.98898125e-04, 1.99508667e-04, 2.99215317e-04, 1.99460983e-04]),\n",
       " 'std_score_time': array([0.00442786, 0.0004572 , 0.00039892, 0.00040064, 0.00045717,\n",
       "        0.00045706, 0.00039892, 0.0004571 , 0.00039887, 0.00039887,\n",
       "        0.00045702, 0.00045706, 0.00029912, 0.00039892, 0.00039883,\n",
       "        0.00039887, 0.        , 0.00045702, 0.00039887, 0.00048791,\n",
       "        0.00045539, 0.00048864, 0.00045699, 0.00045702, 0.00039887,\n",
       "        0.00039892, 0.00029912, 0.00048872, 0.00039897, 0.        ,\n",
       "        0.00029926, 0.00039892, 0.00039892, 0.00045706, 0.00039897,\n",
       "        0.00039892, 0.00045706, 0.00039892, 0.00039907, 0.00029898,\n",
       "        0.00039907, 0.00039921, 0.00039911, 0.00039892, 0.00039887,\n",
       "        0.00039907, 0.00029941, 0.00046473, 0.00029926, 0.00045724,\n",
       "        0.00030012, 0.00030055, 0.00045746, 0.00045628, 0.00045699,\n",
       "        0.00039902, 0.00045695, 0.00039892, 0.00039892, 0.        ,\n",
       "        0.00045761, 0.00038557, 0.00044851, 0.000406  , 0.00048855,\n",
       "        0.00039883, 0.00039902, 0.00039802, 0.0004079 , 0.0003975 ,\n",
       "        0.00038543, 0.00045208, 0.00047895, 0.00050226, 0.        ,\n",
       "        0.00030191, 0.00049783, 0.00049151, 0.00045699, 0.00039892,\n",
       "        0.00040054, 0.00048984, 0.00039716, 0.00039959, 0.00045601,\n",
       "        0.00039849, 0.00039897, 0.00029912, 0.0004571 , 0.00045735,\n",
       "        0.00039897, 0.00029933, 0.00045713, 0.00039902, 0.00039902,\n",
       "        0.00048899, 0.00039864, 0.00045254, 0.00045733, 0.00045742,\n",
       "        0.00039887, 0.00040479, 0.00039911, 0.00045782, 0.00045746,\n",
       "        0.00046199, 0.00030141, 0.00045659, 0.00039868, 0.00029898,\n",
       "        0.00039902, 0.0004571 , 0.00029926, 0.00029919, 0.00045702,\n",
       "        0.00045699, 0.00029912, 0.00039868, 0.00045688, 0.00039887,\n",
       "        0.00039892, 0.00029912, 0.00039897, 0.00039897, 0.00039902,\n",
       "        0.00039892, 0.00039897, 0.00039892, 0.00048869, 0.00045706,\n",
       "        0.        , 0.00039821, 0.00045713, 0.00039911, 0.00039887,\n",
       "        0.00039897, 0.0004571 , 0.00029919, 0.00045699, 0.00039887,\n",
       "        0.00048855, 0.00039883, 0.00039892, 0.00045713, 0.00039892,\n",
       "        0.00029919, 0.00039897, 0.00039892, 0.00039892, 0.00048455,\n",
       "        0.00039887, 0.00045702, 0.00029941, 0.00039892, 0.00048872,\n",
       "        0.00045669, 0.00045403, 0.00049245, 0.00046235, 0.00039859,\n",
       "        0.00048887, 0.00049851, 0.00039945, 0.00039892, 0.00048887,\n",
       "        0.00048867, 0.00046193, 0.00048946, 0.00049504, 0.0004571 ,\n",
       "        0.00039902, 0.00048878, 0.00048878, 0.00039892, 0.00039887,\n",
       "        0.00045684, 0.00039883, 0.00029919, 0.00048861, 0.00039911,\n",
       "        0.00029869, 0.00040575, 0.0004567 , 0.00039845, 0.00045135,\n",
       "        0.00039547, 0.00029926, 0.00045684, 0.00039892, 0.00039892,\n",
       "        0.00045702, 0.00039887, 0.00029919, 0.00039887, 0.0008444 ,\n",
       "        0.00029926, 0.00048855, 0.00039902, 0.00045706, 0.00039892]),\n",
       " 'param_alpha': masked_array(data=[0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.000325,\n",
       "                    0.000325, 0.000325, 0.000325, 0.000325, 0.000325,\n",
       "                    0.000325, 0.000325, 0.000325, 0.000325, 0.000325,\n",
       "                    0.000325, 0.000325, 0.000325, 0.000325, 0.000325,\n",
       "                    0.000325, 0.000325, 0.000325, 0.000325, 0.000325,\n",
       "                    0.000325, 0.000325, 0.000325, 0.000325, 0.000325,\n",
       "                    0.000325, 0.000325, 0.000325, 0.000325, 0.000325,\n",
       "                    0.000325, 0.000325, 0.000325, 0.000325, 0.000325,\n",
       "                    0.000325, 0.000325, 0.000325, 0.000325, 0.00055,\n",
       "                    0.00055, 0.00055, 0.00055, 0.00055, 0.00055, 0.00055,\n",
       "                    0.00055, 0.00055, 0.00055, 0.00055, 0.00055, 0.00055,\n",
       "                    0.00055, 0.00055, 0.00055, 0.00055, 0.00055, 0.00055,\n",
       "                    0.00055, 0.00055, 0.00055, 0.00055, 0.00055, 0.00055,\n",
       "                    0.00055, 0.00055, 0.00055, 0.00055, 0.00055, 0.00055,\n",
       "                    0.00055, 0.00055, 0.00055, 0.00055, 0.00055, 0.00055,\n",
       "                    0.00055, 0.00055, 0.00055, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.0007750000000000001,\n",
       "                    0.0007750000000000001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_loss': masked_array(data=['hinge', 'hinge', 'hinge', 'hinge', 'hinge', 'hinge',\n",
       "                    'hinge', 'hinge', 'hinge', 'hinge', 'log', 'log',\n",
       "                    'log', 'log', 'log', 'log', 'log', 'log', 'log', 'log',\n",
       "                    'squared_hinge', 'squared_hinge', 'squared_hinge',\n",
       "                    'squared_hinge', 'squared_hinge', 'squared_hinge',\n",
       "                    'squared_hinge', 'squared_hinge', 'squared_hinge',\n",
       "                    'squared_hinge', 'squared_loss', 'squared_loss',\n",
       "                    'squared_loss', 'squared_loss', 'squared_loss',\n",
       "                    'squared_loss', 'squared_loss', 'squared_loss',\n",
       "                    'squared_loss', 'squared_loss', 'hinge', 'hinge',\n",
       "                    'hinge', 'hinge', 'hinge', 'hinge', 'hinge', 'hinge',\n",
       "                    'hinge', 'hinge', 'log', 'log', 'log', 'log', 'log',\n",
       "                    'log', 'log', 'log', 'log', 'log', 'squared_hinge',\n",
       "                    'squared_hinge', 'squared_hinge', 'squared_hinge',\n",
       "                    'squared_hinge', 'squared_hinge', 'squared_hinge',\n",
       "                    'squared_hinge', 'squared_hinge', 'squared_hinge',\n",
       "                    'squared_loss', 'squared_loss', 'squared_loss',\n",
       "                    'squared_loss', 'squared_loss', 'squared_loss',\n",
       "                    'squared_loss', 'squared_loss', 'squared_loss',\n",
       "                    'squared_loss', 'hinge', 'hinge', 'hinge', 'hinge',\n",
       "                    'hinge', 'hinge', 'hinge', 'hinge', 'hinge', 'hinge',\n",
       "                    'log', 'log', 'log', 'log', 'log', 'log', 'log', 'log',\n",
       "                    'log', 'log', 'squared_hinge', 'squared_hinge',\n",
       "                    'squared_hinge', 'squared_hinge', 'squared_hinge',\n",
       "                    'squared_hinge', 'squared_hinge', 'squared_hinge',\n",
       "                    'squared_hinge', 'squared_hinge', 'squared_loss',\n",
       "                    'squared_loss', 'squared_loss', 'squared_loss',\n",
       "                    'squared_loss', 'squared_loss', 'squared_loss',\n",
       "                    'squared_loss', 'squared_loss', 'squared_loss',\n",
       "                    'hinge', 'hinge', 'hinge', 'hinge', 'hinge', 'hinge',\n",
       "                    'hinge', 'hinge', 'hinge', 'hinge', 'log', 'log',\n",
       "                    'log', 'log', 'log', 'log', 'log', 'log', 'log', 'log',\n",
       "                    'squared_hinge', 'squared_hinge', 'squared_hinge',\n",
       "                    'squared_hinge', 'squared_hinge', 'squared_hinge',\n",
       "                    'squared_hinge', 'squared_hinge', 'squared_hinge',\n",
       "                    'squared_hinge', 'squared_loss', 'squared_loss',\n",
       "                    'squared_loss', 'squared_loss', 'squared_loss',\n",
       "                    'squared_loss', 'squared_loss', 'squared_loss',\n",
       "                    'squared_loss', 'squared_loss', 'hinge', 'hinge',\n",
       "                    'hinge', 'hinge', 'hinge', 'hinge', 'hinge', 'hinge',\n",
       "                    'hinge', 'hinge', 'log', 'log', 'log', 'log', 'log',\n",
       "                    'log', 'log', 'log', 'log', 'log', 'squared_hinge',\n",
       "                    'squared_hinge', 'squared_hinge', 'squared_hinge',\n",
       "                    'squared_hinge', 'squared_hinge', 'squared_hinge',\n",
       "                    'squared_hinge', 'squared_hinge', 'squared_hinge',\n",
       "                    'squared_loss', 'squared_loss', 'squared_loss',\n",
       "                    'squared_loss', 'squared_loss', 'squared_loss',\n",
       "                    'squared_loss', 'squared_loss', 'squared_loss',\n",
       "                    'squared_loss'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_iter': masked_array(data=[5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 5, 5, 6, 6, 7, 7, 8, 8,\n",
       "                    9, 9, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 5, 5, 6, 6, 7, 7,\n",
       "                    8, 8, 9, 9, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 5, 5, 6, 6,\n",
       "                    7, 7, 8, 8, 9, 9, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 5, 5,\n",
       "                    6, 6, 7, 7, 8, 8, 9, 9, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 5, 5, 6, 6, 7, 7, 8, 8,\n",
       "                    9, 9, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 5, 5, 6, 6, 7, 7,\n",
       "                    8, 8, 9, 9, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 5, 5, 6, 6,\n",
       "                    7, 7, 8, 8, 9, 9, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 5, 5,\n",
       "                    6, 6, 7, 7, 8, 8, 9, 9, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 5, 5, 6, 6, 7, 7, 8, 8,\n",
       "                    9, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2',\n",
       "                    'l1', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 5, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 5, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 6, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 6, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 7, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 7, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 8, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 8, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 9, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 9, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'log', 'max_iter': 5, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'log', 'max_iter': 5, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'log', 'max_iter': 6, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'log', 'max_iter': 6, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'log', 'max_iter': 7, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'log', 'max_iter': 7, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'log', 'max_iter': 8, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'log', 'max_iter': 8, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'log', 'max_iter': 9, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'log', 'max_iter': 9, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_hinge', 'max_iter': 5, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_hinge', 'max_iter': 5, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_hinge', 'max_iter': 6, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_hinge', 'max_iter': 6, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_hinge', 'max_iter': 7, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_hinge', 'max_iter': 7, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_hinge', 'max_iter': 8, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_hinge', 'max_iter': 8, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_hinge', 'max_iter': 9, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_hinge', 'max_iter': 9, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_loss', 'max_iter': 5, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_loss', 'max_iter': 5, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_loss', 'max_iter': 6, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_loss', 'max_iter': 6, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_loss', 'max_iter': 7, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_loss', 'max_iter': 7, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_loss', 'max_iter': 8, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_loss', 'max_iter': 8, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_loss', 'max_iter': 9, 'penalty': 'l1'},\n",
       "  {'alpha': 0.0001, 'loss': 'squared_loss', 'max_iter': 9, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'hinge', 'max_iter': 5, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'hinge', 'max_iter': 5, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'hinge', 'max_iter': 6, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'hinge', 'max_iter': 6, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'hinge', 'max_iter': 7, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'hinge', 'max_iter': 7, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'hinge', 'max_iter': 8, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'hinge', 'max_iter': 8, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'hinge', 'max_iter': 9, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'hinge', 'max_iter': 9, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'log', 'max_iter': 5, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'log', 'max_iter': 5, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'log', 'max_iter': 6, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'log', 'max_iter': 6, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'log', 'max_iter': 7, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'log', 'max_iter': 7, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'log', 'max_iter': 8, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'log', 'max_iter': 8, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'log', 'max_iter': 9, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'log', 'max_iter': 9, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_hinge', 'max_iter': 5, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_hinge', 'max_iter': 5, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_hinge', 'max_iter': 6, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_hinge', 'max_iter': 6, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_hinge', 'max_iter': 7, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_hinge', 'max_iter': 7, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_hinge', 'max_iter': 8, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_hinge', 'max_iter': 8, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_hinge', 'max_iter': 9, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_hinge', 'max_iter': 9, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_loss', 'max_iter': 5, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_loss', 'max_iter': 5, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_loss', 'max_iter': 6, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_loss', 'max_iter': 6, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_loss', 'max_iter': 7, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_loss', 'max_iter': 7, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_loss', 'max_iter': 8, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_loss', 'max_iter': 8, 'penalty': 'l2'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_loss', 'max_iter': 9, 'penalty': 'l1'},\n",
       "  {'alpha': 0.000325, 'loss': 'squared_loss', 'max_iter': 9, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'hinge', 'max_iter': 5, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'hinge', 'max_iter': 5, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'hinge', 'max_iter': 6, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'hinge', 'max_iter': 6, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'hinge', 'max_iter': 7, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'hinge', 'max_iter': 7, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'hinge', 'max_iter': 8, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'hinge', 'max_iter': 8, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'hinge', 'max_iter': 9, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'hinge', 'max_iter': 9, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'log', 'max_iter': 5, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'log', 'max_iter': 5, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'log', 'max_iter': 6, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'log', 'max_iter': 6, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'log', 'max_iter': 7, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'log', 'max_iter': 7, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'log', 'max_iter': 8, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'log', 'max_iter': 8, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'log', 'max_iter': 9, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'log', 'max_iter': 9, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_hinge', 'max_iter': 5, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_hinge', 'max_iter': 5, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_hinge', 'max_iter': 6, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_hinge', 'max_iter': 6, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_hinge', 'max_iter': 7, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_hinge', 'max_iter': 7, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_hinge', 'max_iter': 8, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_hinge', 'max_iter': 8, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_hinge', 'max_iter': 9, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_hinge', 'max_iter': 9, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_loss', 'max_iter': 5, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_loss', 'max_iter': 5, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_loss', 'max_iter': 6, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_loss', 'max_iter': 6, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_loss', 'max_iter': 7, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_loss', 'max_iter': 7, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_loss', 'max_iter': 8, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_loss', 'max_iter': 8, 'penalty': 'l2'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_loss', 'max_iter': 9, 'penalty': 'l1'},\n",
       "  {'alpha': 0.00055, 'loss': 'squared_loss', 'max_iter': 9, 'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'hinge',\n",
       "   'max_iter': 5,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'hinge',\n",
       "   'max_iter': 5,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'hinge',\n",
       "   'max_iter': 6,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'hinge',\n",
       "   'max_iter': 6,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'hinge',\n",
       "   'max_iter': 7,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'hinge',\n",
       "   'max_iter': 7,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'hinge',\n",
       "   'max_iter': 8,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'hinge',\n",
       "   'max_iter': 8,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'hinge',\n",
       "   'max_iter': 9,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'hinge',\n",
       "   'max_iter': 9,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'log',\n",
       "   'max_iter': 5,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'log',\n",
       "   'max_iter': 5,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'log',\n",
       "   'max_iter': 6,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'log',\n",
       "   'max_iter': 6,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'log',\n",
       "   'max_iter': 7,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'log',\n",
       "   'max_iter': 7,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'log',\n",
       "   'max_iter': 8,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'log',\n",
       "   'max_iter': 8,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'log',\n",
       "   'max_iter': 9,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'log',\n",
       "   'max_iter': 9,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_hinge',\n",
       "   'max_iter': 5,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_hinge',\n",
       "   'max_iter': 5,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_hinge',\n",
       "   'max_iter': 6,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_hinge',\n",
       "   'max_iter': 6,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_hinge',\n",
       "   'max_iter': 7,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_hinge',\n",
       "   'max_iter': 7,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_hinge',\n",
       "   'max_iter': 8,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_hinge',\n",
       "   'max_iter': 8,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_hinge',\n",
       "   'max_iter': 9,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_hinge',\n",
       "   'max_iter': 9,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_loss',\n",
       "   'max_iter': 5,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_loss',\n",
       "   'max_iter': 5,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_loss',\n",
       "   'max_iter': 6,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_loss',\n",
       "   'max_iter': 6,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_loss',\n",
       "   'max_iter': 7,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_loss',\n",
       "   'max_iter': 7,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_loss',\n",
       "   'max_iter': 8,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_loss',\n",
       "   'max_iter': 8,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_loss',\n",
       "   'max_iter': 9,\n",
       "   'penalty': 'l1'},\n",
       "  {'alpha': 0.0007750000000000001,\n",
       "   'loss': 'squared_loss',\n",
       "   'max_iter': 9,\n",
       "   'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 5, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 5, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 6, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 6, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 7, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 7, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 8, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 8, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 9, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'hinge', 'max_iter': 9, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'log', 'max_iter': 5, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'log', 'max_iter': 5, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'log', 'max_iter': 6, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'log', 'max_iter': 6, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'log', 'max_iter': 7, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'log', 'max_iter': 7, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'log', 'max_iter': 8, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'log', 'max_iter': 8, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'log', 'max_iter': 9, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'log', 'max_iter': 9, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_hinge', 'max_iter': 5, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_hinge', 'max_iter': 5, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_hinge', 'max_iter': 6, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_hinge', 'max_iter': 6, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_hinge', 'max_iter': 7, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_hinge', 'max_iter': 7, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_hinge', 'max_iter': 8, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_hinge', 'max_iter': 8, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_hinge', 'max_iter': 9, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_hinge', 'max_iter': 9, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_loss', 'max_iter': 5, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_loss', 'max_iter': 5, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_loss', 'max_iter': 6, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_loss', 'max_iter': 6, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_loss', 'max_iter': 7, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_loss', 'max_iter': 7, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_loss', 'max_iter': 8, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_loss', 'max_iter': 8, 'penalty': 'l2'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_loss', 'max_iter': 9, 'penalty': 'l1'},\n",
       "  {'alpha': 0.001, 'loss': 'squared_loss', 'max_iter': 9, 'penalty': 'l2'}],\n",
       " 'split0_test_score': array([0.76190476, 0.71428571, 0.71428571, 0.71428571, 0.66666667,\n",
       "        0.9047619 , 0.71428571, 0.80952381, 0.71428571, 0.71428571,\n",
       "        0.80952381, 0.71428571, 0.71428571, 0.71428571, 0.57142857,\n",
       "        0.85714286, 0.76190476, 0.76190476, 0.71428571, 0.71428571,\n",
       "        0.80952381, 0.71428571, 0.71428571, 0.71428571, 0.85714286,\n",
       "        0.9047619 , 0.85714286, 0.76190476, 0.71428571, 0.71428571,\n",
       "        0.28571429, 0.28571429, 0.38095238, 0.38095238, 0.28571429,\n",
       "        0.28571429, 0.23809524, 0.38095238, 0.28571429, 0.28571429,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.9047619 ,\n",
       "        0.85714286, 0.85714286, 0.71428571, 0.71428571, 0.66666667,\n",
       "        0.80952381, 0.71428571, 0.71428571, 0.71428571, 0.95238095,\n",
       "        0.76190476, 0.9047619 , 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.80952381, 0.76190476, 0.71428571, 0.71428571, 0.9047619 ,\n",
       "        0.76190476, 0.71428571, 0.76190476, 0.71428571, 0.71428571,\n",
       "        0.28571429, 0.28571429, 0.33333333, 0.38095238, 0.38095238,\n",
       "        0.38095238, 0.38095238, 0.33333333, 0.38095238, 0.28571429,\n",
       "        0.71428571, 0.76190476, 0.71428571, 0.71428571, 0.95238095,\n",
       "        0.85714286, 0.9047619 , 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.76190476, 0.71428571, 0.71428571, 0.71428571, 0.85714286,\n",
       "        0.9047619 , 0.76190476, 0.71428571, 0.76190476, 0.71428571,\n",
       "        0.9047619 , 0.71428571, 0.71428571, 0.71428571, 0.9047619 ,\n",
       "        0.66666667, 0.9047619 , 0.9047619 , 0.76190476, 0.71428571,\n",
       "        0.28571429, 0.33333333, 0.        , 0.28571429, 0.        ,\n",
       "        0.38095238, 0.38095238, 0.33333333, 0.28571429, 0.38095238,\n",
       "        0.80952381, 0.71428571, 0.71428571, 0.71428571, 0.9047619 ,\n",
       "        0.85714286, 0.76190476, 0.66666667, 0.80952381, 0.66666667,\n",
       "        0.9047619 , 0.71428571, 0.71428571, 0.71428571, 0.9047619 ,\n",
       "        0.47619048, 0.76190476, 0.71428571, 0.80952381, 0.71428571,\n",
       "        0.71428571, 0.76190476, 0.71428571, 0.71428571, 0.9047619 ,\n",
       "        0.85714286, 0.9047619 , 0.80952381, 0.71428571, 0.71428571,\n",
       "        0.38095238, 0.        , 0.71428571, 0.33333333, 0.66666667,\n",
       "        0.61904762, 0.33333333, 0.38095238, 0.33333333, 0.38095238,\n",
       "        0.76190476, 0.71428571, 0.71428571, 0.71428571, 0.95238095,\n",
       "        0.66666667, 0.9047619 , 0.71428571, 0.76190476, 0.71428571,\n",
       "        0.95238095, 0.71428571, 0.71428571, 0.71428571, 0.9047619 ,\n",
       "        0.95238095, 0.76190476, 0.71428571, 0.80952381, 0.66666667,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.9047619 ,\n",
       "        0.9047619 , 0.80952381, 0.76190476, 0.71428571, 0.71428571,\n",
       "        0.28571429, 0.33333333, 0.71428571, 0.38095238, 0.33333333,\n",
       "        0.28571429, 0.28571429, 0.28571429, 0.28571429, 0.38095238]),\n",
       " 'split1_test_score': array([0.80952381, 0.61904762, 0.76190476, 0.85714286, 0.71428571,\n",
       "        0.71428571, 1.        , 0.61904762, 0.71428571, 0.71428571,\n",
       "        0.80952381, 0.71428571, 0.61904762, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.95238095, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.95238095, 0.61904762, 1.        , 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.95238095, 0.95238095, 0.71428571, 0.80952381,\n",
       "        0.28571429, 0.28571429, 0.33333333, 0.33333333, 0.38095238,\n",
       "        0.38095238, 0.38095238, 0.42857143, 0.28571429, 0.33333333,\n",
       "        0.80952381, 0.61904762, 1.        , 0.9047619 , 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.80952381, 0.71428571, 0.71428571,\n",
       "        1.        , 0.76190476, 1.        , 0.71428571, 0.71428571,\n",
       "        0.71428571, 1.        , 0.95238095, 0.71428571, 0.71428571,\n",
       "        0.66666667, 0.71428571, 0.95238095, 0.76190476, 0.71428571,\n",
       "        0.71428571, 1.        , 0.85714286, 0.71428571, 0.71428571,\n",
       "        0.38095238, 0.38095238, 0.38095238, 0.33333333, 0.28571429,\n",
       "        0.33333333, 0.38095238, 0.33333333, 0.28571429, 0.33333333,\n",
       "        0.66666667, 0.61904762, 0.95238095, 0.9047619 , 0.71428571,\n",
       "        0.71428571, 0.95238095, 0.85714286, 0.71428571, 0.71428571,\n",
       "        0.95238095, 0.85714286, 1.        , 0.76190476, 0.71428571,\n",
       "        0.71428571, 0.9047619 , 0.85714286, 0.76190476, 0.71428571,\n",
       "        0.61904762, 0.95238095, 1.        , 0.95238095, 0.71428571,\n",
       "        0.71428571, 0.85714286, 0.85714286, 0.9047619 , 0.76190476,\n",
       "        0.33333333, 0.33333333, 0.28571429, 0.42857143, 0.38095238,\n",
       "        0.28571429, 0.33333333, 0.33333333, 0.28571429, 0.28571429,\n",
       "        1.        , 0.61904762, 0.95238095, 0.95238095, 0.71428571,\n",
       "        0.71428571, 0.95238095, 0.85714286, 0.71428571, 0.76190476,\n",
       "        1.        , 0.80952381, 1.        , 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.9047619 , 0.9047619 , 0.71428571,\n",
       "        0.95238095, 0.85714286, 0.95238095, 0.80952381, 0.71428571,\n",
       "        1.        , 0.95238095, 0.85714286, 0.95238095, 0.71428571,\n",
       "        0.38095238, 0.38095238, 0.28571429, 0.38095238, 0.47619048,\n",
       "        0.28571429, 0.33333333, 0.28571429, 0.33333333, 0.38095238,\n",
       "        1.        , 0.61904762, 1.        , 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.85714286, 0.95238095, 0.85714286, 0.71428571,\n",
       "        0.85714286, 0.61904762, 1.        , 0.95238095, 0.9047619 ,\n",
       "        0.71428571, 0.95238095, 1.        , 0.9047619 , 0.71428571,\n",
       "        0.95238095, 0.85714286, 1.        , 0.71428571, 0.71428571,\n",
       "        0.71428571, 1.        , 1.        , 0.95238095, 0.71428571,\n",
       "        0.38095238, 0.38095238, 0.38095238, 0.38095238, 0.28571429,\n",
       "        0.38095238, 0.38095238, 0.38095238, 0.38095238, 0.33333333]),\n",
       " 'split2_test_score': array([0.52380952, 0.38095238, 0.71428571, 0.9047619 , 0.66666667,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.52380952, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.66666667, 0.71428571, 0.71428571,\n",
       "        0.57142857, 0.38095238, 0.85714286, 0.71428571, 0.47619048,\n",
       "        0.71428571, 0.66666667, 0.9047619 , 0.66666667, 0.71428571,\n",
       "        0.33333333, 0.28571429, 0.        , 0.28571429, 0.33333333,\n",
       "        0.28571429, 0.        , 0.28571429, 0.38095238, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.42857143, 0.85714286, 0.95238095, 0.71428571, 0.71428571,\n",
       "        0.47619048, 0.66666667, 0.71428571, 0.38095238, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.66666667, 0.52380952, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.42857143, 0.95238095, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.28571429, 0.33333333, 0.        , 0.61904762, 0.28571429,\n",
       "        0.28571429, 0.42857143, 0.33333333, 0.33333333, 0.33333333,\n",
       "        0.76190476, 0.71428571, 0.71428571, 0.9047619 , 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.66666667, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.85714286, 0.71428571, 0.71428571,\n",
       "        0.66666667, 0.47619048, 0.66666667, 0.71428571, 0.95238095,\n",
       "        0.38095238, 0.71428571, 0.95238095, 0.71428571, 0.71428571,\n",
       "        0.28571429, 0.38095238, 0.0952381 , 0.28571429, 0.33333333,\n",
       "        0.28571429, 0.42857143, 0.28571429, 0.38095238, 0.33333333,\n",
       "        0.66666667, 0.66666667, 0.71428571, 0.85714286, 1.        ,\n",
       "        0.42857143, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.66666667, 0.33333333, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.33333333, 0.71428571, 0.95238095, 0.71428571, 0.71428571,\n",
       "        0.61904762, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.95238095, 0.71428571, 0.71428571,\n",
       "        0.28571429, 0.38095238, 0.33333333, 0.38095238, 0.28571429,\n",
       "        0.38095238, 0.33333333, 0.33333333, 0.33333333, 0.28571429,\n",
       "        0.66666667, 0.71428571, 0.71428571, 0.71428571, 0.95238095,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.66666667, 0.71428571, 0.71428571, 0.38095238, 0.85714286,\n",
       "        0.71428571, 0.9047619 , 0.71428571, 0.85714286, 0.71428571,\n",
       "        0.80952381, 0.71428571, 1.        , 0.71428571, 0.9047619 ,\n",
       "        0.71428571, 0.95238095, 0.71428571, 0.95238095, 0.71428571,\n",
       "        0.71428571, 0.28571429, 0.38095238, 0.38095238, 0.33333333,\n",
       "        0.28571429, 0.33333333, 0.28571429, 0.71428571, 0.38095238]),\n",
       " 'split3_test_score': array([0.61904762, 0.61904762, 0.71428571, 0.71428571, 0.85714286,\n",
       "        0.61904762, 0.76190476, 0.95238095, 0.71428571, 0.57142857,\n",
       "        1.        , 0.80952381, 0.71428571, 0.71428571, 0.61904762,\n",
       "        0.61904762, 0.95238095, 0.85714286, 0.71428571, 0.71428571,\n",
       "        0.95238095, 0.85714286, 0.71428571, 0.71428571, 0.80952381,\n",
       "        0.80952381, 0.80952381, 0.95238095, 0.71428571, 0.71428571,\n",
       "        0.28571429, 0.28571429, 0.28571429, 0.28571429, 0.33333333,\n",
       "        0.33333333, 0.33333333, 0.38095238, 0.38095238, 0.38095238,\n",
       "        0.95238095, 0.76190476, 0.95238095, 0.71428571, 0.61904762,\n",
       "        0.61904762, 1.        , 0.95238095, 0.61904762, 0.33333333,\n",
       "        0.95238095, 0.95238095, 0.71428571, 0.71428571, 0.61904762,\n",
       "        0.61904762, 0.95238095, 0.95238095, 0.76190476, 0.33333333,\n",
       "        0.57142857, 0.71428571, 0.76190476, 0.71428571, 1.        ,\n",
       "        0.61904762, 0.80952381, 0.76190476, 1.        , 0.57142857,\n",
       "        0.28571429, 0.38095238, 0.38095238, 0.33333333, 0.33333333,\n",
       "        0.        , 0.28571429, 0.33333333, 0.33333333, 0.33333333,\n",
       "        1.        , 0.57142857, 0.71428571, 0.71428571, 0.76190476,\n",
       "        0.61904762, 1.        , 0.28571429, 0.95238095, 0.33333333,\n",
       "        1.        , 0.71428571, 0.71428571, 0.71428571, 0.61904762,\n",
       "        0.57142857, 0.9047619 , 0.95238095, 0.57142857, 0.71428571,\n",
       "        0.9047619 , 0.57142857, 0.71428571, 0.71428571, 0.61904762,\n",
       "        0.57142857, 0.95238095, 0.9047619 , 1.        , 0.33333333,\n",
       "        0.33333333, 0.28571429, 0.66666667, 0.28571429, 0.28571429,\n",
       "        0.28571429, 0.28571429, 0.33333333, 0.38095238, 0.38095238,\n",
       "        0.95238095, 0.95238095, 0.76190476, 0.71428571, 0.61904762,\n",
       "        0.61904762, 1.        , 0.95238095, 1.        , 0.57142857,\n",
       "        1.        , 0.71428571, 0.71428571, 0.71428571, 0.57142857,\n",
       "        0.61904762, 0.95238095, 0.95238095, 0.76190476, 0.71428571,\n",
       "        0.71428571, 0.57142857, 0.71428571, 0.71428571, 0.80952381,\n",
       "        0.61904762, 0.85714286, 0.76190476, 0.85714286, 0.71428571,\n",
       "        0.28571429, 0.38095238, 0.28571429, 0.38095238, 0.38095238,\n",
       "        0.33333333, 0.33333333, 0.28571429, 0.33333333, 0.38095238,\n",
       "        0.76190476, 0.57142857, 0.71428571, 0.71428571, 0.61904762,\n",
       "        0.61904762, 1.        , 1.        , 0.95238095, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.57142857, 0.71428571, 0.57142857, 0.71428571, 0.61904762,\n",
       "        0.71428571, 0.71428571, 0.95238095, 0.71428571, 0.95238095,\n",
       "        1.        , 0.95238095, 0.95238095, 0.95238095, 0.71428571,\n",
       "        0.04761905, 0.28571429, 0.71428571, 0.38095238, 0.38095238,\n",
       "        0.38095238, 0.61904762, 0.28571429, 0.28571429, 0.04761905]),\n",
       " 'split4_test_score': array([0.47619048, 0.71428571, 0.76190476, 0.76190476, 0.80952381,\n",
       "        0.85714286, 0.47619048, 1.        , 0.61904762, 0.57142857,\n",
       "        0.71428571, 0.85714286, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.57142857, 0.9047619 , 1.        , 0.61904762, 0.57142857,\n",
       "        0.66666667, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 1.        , 0.85714286, 0.95238095, 0.42857143,\n",
       "        0.38095238, 0.33333333, 0.71428571, 0.38095238, 0.38095238,\n",
       "        0.38095238, 0.33333333, 0.28571429, 0.71428571, 0.28571429,\n",
       "        0.85714286, 0.71428571, 0.95238095, 0.76190476, 0.76190476,\n",
       "        0.71428571, 0.57142857, 0.28571429, 0.85714286, 0.71428571,\n",
       "        1.        , 0.80952381, 0.71428571, 0.71428571, 0.9047619 ,\n",
       "        0.71428571, 0.85714286, 0.61904762, 0.76190476, 0.85714286,\n",
       "        0.52380952, 0.71428571, 0.71428571, 0.85714286, 0.71428571,\n",
       "        0.71428571, 0.85714286, 0.28571429, 0.76190476, 0.85714286,\n",
       "        0.28571429, 0.38095238, 0.38095238, 0.38095238, 0.19047619,\n",
       "        0.14285714, 0.33333333, 0.38095238, 0.28571429, 0.28571429,\n",
       "        0.76190476, 0.71428571, 0.71428571, 0.71428571, 1.        ,\n",
       "        0.76190476, 0.71428571, 0.28571429, 0.76190476, 0.61904762,\n",
       "        0.95238095, 0.28571429, 0.95238095, 0.71428571, 1.        ,\n",
       "        0.76190476, 0.85714286, 0.85714286, 0.85714286, 0.61904762,\n",
       "        0.85714286, 0.42857143, 0.71428571, 0.71428571, 0.85714286,\n",
       "        0.76190476, 0.76190476, 0.57142857, 0.85714286, 0.85714286,\n",
       "        0.38095238, 0.38095238, 0.71428571, 0.        , 0.33333333,\n",
       "        0.0952381 , 0.33333333, 0.28571429, 0.28571429, 0.38095238,\n",
       "        0.61904762, 0.76190476, 0.95238095, 0.71428571, 1.        ,\n",
       "        0.71428571, 0.61904762, 0.85714286, 0.85714286, 0.61904762,\n",
       "        0.85714286, 0.47619048, 0.95238095, 0.71428571, 0.9047619 ,\n",
       "        0.71428571, 0.85714286, 0.9047619 , 0.71428571, 0.57142857,\n",
       "        0.9047619 , 0.28571429, 0.71428571, 0.71428571, 0.76190476,\n",
       "        0.71428571, 0.9047619 , 0.80952381, 0.85714286, 0.9047619 ,\n",
       "        0.38095238, 0.38095238, 0.14285714, 0.66666667, 0.66666667,\n",
       "        0.28571429, 0.38095238, 0.28571429, 0.71428571, 0.28571429,\n",
       "        0.71428571, 0.85714286, 0.71428571, 0.76190476, 0.9047619 ,\n",
       "        0.76190476, 0.9047619 , 0.85714286, 0.85714286, 0.85714286,\n",
       "        0.66666667, 0.85714286, 0.71428571, 0.76190476, 1.        ,\n",
       "        0.85714286, 0.85714286, 1.        , 0.85714286, 0.85714286,\n",
       "        0.85714286, 0.76190476, 0.71428571, 0.71428571, 0.85714286,\n",
       "        0.71428571, 0.52380952, 0.33333333, 0.71428571, 0.9047619 ,\n",
       "        0.28571429, 0.28571429, 0.28571429, 0.        , 0.28571429,\n",
       "        0.33333333, 0.28571429, 0.28571429, 0.47619048, 0.        ]),\n",
       " 'split5_test_score': array([0.57142857, 0.33333333, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.76190476, 0.80952381, 0.42857143, 0.85714286, 0.76190476,\n",
       "        0.61904762, 0.61904762, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.66666667, 0.42857143, 0.38095238, 0.95238095, 0.71428571,\n",
       "        0.61904762, 0.61904762, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.95238095, 0.71428571, 0.71428571, 0.85714286,\n",
       "        0.38095238, 0.23809524, 0.04761905, 0.28571429, 0.        ,\n",
       "        0.38095238, 0.33333333, 0.38095238, 0.38095238, 0.38095238,\n",
       "        0.61904762, 0.61904762, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.76190476, 0.9047619 , 0.42857143, 0.85714286, 0.85714286,\n",
       "        0.61904762, 0.52380952, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.61904762, 0.33333333, 0.71428571, 0.95238095,\n",
       "        0.47619048, 0.61904762, 1.        , 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.95238095, 0.71428571, 1.        , 0.95238095,\n",
       "        0.38095238, 0.28571429, 0.28571429, 0.38095238, 0.33333333,\n",
       "        0.38095238, 0.33333333, 0.        , 0.33333333, 0.33333333,\n",
       "        0.61904762, 0.38095238, 1.        , 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.85714286, 0.42857143, 1.        , 0.95238095,\n",
       "        0.52380952, 0.57142857, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.38095238, 1.        , 0.95238095,\n",
       "        0.61904762, 0.61904762, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.76190476, 0.85714286, 0.42857143, 0.76190476, 0.9047619 ,\n",
       "        0.28571429, 0.33333333, 0.38095238, 0.28571429, 0.28571429,\n",
       "        0.28571429, 0.33333333, 0.33333333, 0.57142857, 0.        ,\n",
       "        0.61904762, 0.42857143, 1.        , 0.71428571, 0.71428571,\n",
       "        0.71428571, 1.        , 0.42857143, 1.        , 0.9047619 ,\n",
       "        0.47619048, 0.38095238, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.95238095, 0.42857143, 0.95238095, 0.80952381,\n",
       "        0.61904762, 0.61904762, 0.71428571, 0.71428571, 0.85714286,\n",
       "        0.71428571, 1.        , 0.71428571, 0.85714286, 0.76190476,\n",
       "        0.38095238, 0.38095238, 0.28571429, 0.38095238, 0.38095238,\n",
       "        0.28571429, 0.28571429, 0.47619048, 0.23809524, 0.42857143,\n",
       "        0.61904762, 0.42857143, 0.85714286, 0.71428571, 0.71428571,\n",
       "        0.71428571, 1.        , 0.42857143, 0.85714286, 0.9047619 ,\n",
       "        0.61904762, 0.61904762, 1.        , 0.76190476, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.95238095, 0.95238095,\n",
       "        0.52380952, 0.61904762, 0.95238095, 0.71428571, 0.71428571,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.95238095,\n",
       "        0.38095238, 0.38095238, 0.28571429, 0.38095238, 0.33333333,\n",
       "        0.38095238, 0.04761905, 0.        , 0.38095238, 0.0952381 ]),\n",
       " 'split6_test_score': array([1.        , 0.71428571, 0.71428571, 0.71428571, 0.9047619 ,\n",
       "        0.66666667, 0.71428571, 0.71428571, 0.57142857, 0.66666667,\n",
       "        0.71428571, 0.9047619 , 1.        , 0.71428571, 0.80952381,\n",
       "        0.52380952, 0.71428571, 0.71428571, 0.76190476, 0.80952381,\n",
       "        0.71428571, 1.        , 0.95238095, 0.85714286, 0.61904762,\n",
       "        0.61904762, 0.71428571, 0.71428571, 0.52380952, 0.52380952,\n",
       "        0.38095238, 0.38095238, 0.28571429, 0.38095238, 0.33333333,\n",
       "        0.33333333, 0.33333333, 0.38095238, 0.33333333, 0.71428571,\n",
       "        1.        , 0.95238095, 0.95238095, 0.71428571, 0.9047619 ,\n",
       "        0.9047619 , 0.71428571, 0.71428571, 0.95238095, 0.61904762,\n",
       "        0.71428571, 0.71428571, 0.9047619 , 0.71428571, 0.85714286,\n",
       "        0.42857143, 0.71428571, 0.71428571, 0.76190476, 0.9047619 ,\n",
       "        0.66666667, 0.28571429, 0.71428571, 0.71428571, 0.66666667,\n",
       "        0.52380952, 0.71428571, 0.71428571, 0.38095238, 0.28571429,\n",
       "        0.33333333, 0.28571429, 0.52380952, 0.28571429, 0.38095238,\n",
       "        0.33333333, 0.33333333, 0.33333333, 0.28571429, 0.28571429,\n",
       "        0.76190476, 0.71428571, 1.        , 0.71428571, 0.85714286,\n",
       "        0.80952381, 0.71428571, 0.71428571, 0.95238095, 0.52380952,\n",
       "        1.        , 1.        , 0.71428571, 0.71428571, 0.85714286,\n",
       "        0.66666667, 0.71428571, 0.71428571, 0.80952381, 0.57142857,\n",
       "        0.76190476, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        1.        , 0.71428571, 0.71428571, 1.        , 0.61904762,\n",
       "        0.52380952, 0.        , 0.33333333, 0.61904762, 0.38095238,\n",
       "        0.38095238, 0.33333333, 0.28571429, 0.33333333, 0.33333333,\n",
       "        0.9047619 , 1.        , 0.71428571, 0.71428571, 1.        ,\n",
       "        0.80952381, 0.71428571, 0.71428571, 1.        , 1.        ,\n",
       "        0.85714286, 0.71428571, 0.71428571, 0.95238095, 0.85714286,\n",
       "        0.28571429, 0.71428571, 0.71428571, 1.        , 0.9047619 ,\n",
       "        0.85714286, 1.        , 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.28571429, 0.71428571, 0.71428571, 0.76190476, 0.9047619 ,\n",
       "        0.28571429, 0.        , 0.28571429, 0.28571429, 0.38095238,\n",
       "        0.28571429, 0.28571429, 0.66666667, 0.66666667, 0.38095238,\n",
       "        0.95238095, 0.71428571, 0.71428571, 0.71428571, 0.95238095,\n",
       "        0.80952381, 0.76190476, 0.71428571, 0.71428571, 0.57142857,\n",
       "        1.        , 0.9047619 , 0.71428571, 0.71428571, 1.        ,\n",
       "        0.38095238, 0.71428571, 0.71428571, 1.        , 0.47619048,\n",
       "        0.52380952, 0.71428571, 0.71428571, 0.71428571, 0.76190476,\n",
       "        0.66666667, 0.9047619 , 0.71428571, 0.95238095, 0.28571429,\n",
       "        0.38095238, 0.38095238, 0.28571429, 0.28571429, 0.33333333,\n",
       "        0.33333333, 0.28571429, 0.61904762, 0.28571429, 0.        ]),\n",
       " 'split7_test_score': array([0.33333333, 0.71428571, 0.28571429, 0.38095238, 0.9047619 ,\n",
       "        0.76190476, 0.95238095, 0.71428571, 1.        , 0.71428571,\n",
       "        0.33333333, 0.66666667, 0.28571429, 0.28571429, 0.9047619 ,\n",
       "        0.80952381, 0.76190476, 0.85714286, 1.        , 1.        ,\n",
       "        0.38095238, 0.66666667, 0.28571429, 0.28571429, 0.95238095,\n",
       "        0.76190476, 0.76190476, 0.95238095, 0.95238095, 1.        ,\n",
       "        0.38095238, 0.28571429, 0.33333333, 0.33333333, 0.33333333,\n",
       "        0.33333333, 0.38095238, 0.33333333, 0.23809524, 0.28571429,\n",
       "        0.52380952, 0.33333333, 0.47619048, 0.28571429, 0.85714286,\n",
       "        0.80952381, 0.80952381, 0.9047619 , 1.        , 0.71428571,\n",
       "        0.66666667, 0.33333333, 0.28571429, 0.28571429, 0.95238095,\n",
       "        0.76190476, 0.80952381, 0.71428571, 0.80952381, 1.        ,\n",
       "        0.71428571, 0.71428571, 0.47619048, 0.28571429, 0.95238095,\n",
       "        0.76190476, 0.71428571, 0.80952381, 0.95238095, 0.95238095,\n",
       "        0.33333333, 0.28571429, 0.        , 0.71428571, 0.19047619,\n",
       "        0.28571429, 0.14285714, 0.33333333, 0.33333333, 0.23809524,\n",
       "        0.61904762, 0.33333333, 0.52380952, 0.28571429, 1.        ,\n",
       "        0.76190476, 0.95238095, 0.9047619 , 1.        , 0.71428571,\n",
       "        0.71428571, 0.33333333, 0.33333333, 0.28571429, 1.        ,\n",
       "        0.71428571, 0.71428571, 0.80952381, 0.95238095, 0.95238095,\n",
       "        0.76190476, 0.33333333, 0.47619048, 0.28571429, 1.        ,\n",
       "        0.95238095, 0.95238095, 0.95238095, 0.95238095, 0.71428571,\n",
       "        0.33333333, 0.33333333, 0.28571429, 0.38095238, 0.33333333,\n",
       "        0.33333333, 0.38095238, 0.33333333, 0.33333333, 0.28571429,\n",
       "        0.61904762, 0.33333333, 0.61904762, 0.28571429, 1.        ,\n",
       "        0.76190476, 0.9047619 , 0.85714286, 1.        , 0.95238095,\n",
       "        0.71428571, 0.33333333, 0.28571429, 0.28571429, 1.        ,\n",
       "        0.71428571, 1.        , 0.80952381, 0.9047619 , 0.95238095,\n",
       "        0.61904762, 0.33333333, 0.61904762, 0.33333333, 0.95238095,\n",
       "        0.76190476, 1.        , 0.71428571, 0.85714286, 0.9047619 ,\n",
       "        0.33333333, 0.33333333, 0.38095238, 0.71428571, 0.28571429,\n",
       "        0.38095238, 0.28571429, 0.38095238, 0.28571429, 0.38095238,\n",
       "        0.61904762, 0.33333333, 0.61904762, 0.28571429, 0.9047619 ,\n",
       "        0.71428571, 0.95238095, 0.85714286, 1.        , 0.95238095,\n",
       "        0.76190476, 0.33333333, 0.38095238, 0.28571429, 0.85714286,\n",
       "        0.76190476, 1.        , 0.71428571, 0.85714286, 0.95238095,\n",
       "        0.57142857, 0.71428571, 0.61904762, 0.28571429, 1.        ,\n",
       "        0.80952381, 0.71428571, 0.95238095, 1.        , 0.71428571,\n",
       "        0.19047619, 0.28571429, 0.28571429, 0.28571429, 0.33333333,\n",
       "        0.38095238, 0.42857143, 0.33333333, 0.33333333, 0.38095238]),\n",
       " 'split8_test_score': array([0.71428571, 0.71428571, 1.        , 0.76190476, 0.71428571,\n",
       "        0.71428571, 0.80952381, 0.52380952, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.57142857, 0.85714286, 0.71428571,\n",
       "        0.71428571, 1.        , 1.        , 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.95238095, 0.9047619 , 0.71428571,\n",
       "        0.71428571, 1.        , 1.        , 0.71428571, 0.71428571,\n",
       "        0.28571429, 0.28571429, 0.71428571, 0.        , 0.33333333,\n",
       "        0.19047619, 0.        , 0.        , 0.28571429, 0.38095238,\n",
       "        0.76190476, 0.71428571, 0.95238095, 0.85714286, 0.71428571,\n",
       "        0.71428571, 0.76190476, 0.57142857, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 1.        , 0.85714286, 0.76190476,\n",
       "        0.9047619 , 0.95238095, 0.66666667, 0.71428571, 0.71428571,\n",
       "        0.61904762, 0.33333333, 1.        , 0.71428571, 0.71428571,\n",
       "        0.76190476, 0.76190476, 0.95238095, 0.71428571, 0.71428571,\n",
       "        0.28571429, 0.33333333, 0.28571429, 0.57142857, 0.33333333,\n",
       "        0.33333333, 0.33333333, 0.38095238, 0.52380952, 0.33333333,\n",
       "        0.71428571, 0.33333333, 0.9047619 , 0.9047619 , 0.76190476,\n",
       "        0.71428571, 0.95238095, 0.57142857, 0.71428571, 0.71428571,\n",
       "        0.61904762, 0.71428571, 1.        , 0.9047619 , 0.76190476,\n",
       "        0.80952381, 0.85714286, 1.        , 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.85714286, 0.76190476, 0.71428571,\n",
       "        0.71428571, 0.76190476, 0.95238095, 0.71428571, 0.71428571,\n",
       "        0.28571429, 0.28571429, 0.33333333, 0.33333333, 0.28571429,\n",
       "        0.38095238, 0.        , 0.38095238, 0.        , 0.33333333,\n",
       "        0.71428571, 0.71428571, 1.        , 0.85714286, 0.71428571,\n",
       "        0.71428571, 1.        , 0.61904762, 1.        , 0.71428571,\n",
       "        0.71428571, 0.71428571, 1.        , 0.95238095, 0.9047619 ,\n",
       "        0.71428571, 0.76190476, 0.61904762, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.95238095, 0.76190476, 0.71428571,\n",
       "        0.9047619 , 0.9047619 , 0.61904762, 0.71428571, 0.71428571,\n",
       "        0.33333333, 0.33333333, 0.04761905, 0.38095238, 0.33333333,\n",
       "        0.38095238, 0.        , 0.38095238, 0.38095238, 0.28571429,\n",
       "        1.        , 0.71428571, 1.        , 0.85714286, 0.85714286,\n",
       "        0.71428571, 0.9047619 , 0.61904762, 1.        , 0.71428571,\n",
       "        0.71428571, 0.71428571, 1.        , 0.61904762, 1.        ,\n",
       "        0.71428571, 1.        , 0.80952381, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.95238095, 0.9047619 , 0.80952381,\n",
       "        0.71428571, 1.        , 1.        , 0.71428571, 0.71428571,\n",
       "        0.33333333, 0.38095238, 0.28571429, 0.71428571, 0.33333333,\n",
       "        0.        , 0.        , 0.        , 0.38095238, 0.33333333]),\n",
       " 'split9_test_score': array([0.76190476, 0.71428571, 0.61904762, 0.95238095, 0.76190476,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.76190476, 0.9047619 ,\n",
       "        0.71428571, 0.71428571, 0.66666667, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.9047619 , 0.95238095,\n",
       "        0.76190476, 0.71428571, 0.71428571, 0.33333333, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.9047619 , 0.95238095,\n",
       "        0.28571429, 0.38095238, 0.38095238, 0.38095238, 0.38095238,\n",
       "        0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.        ,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.9047619 , 0.9047619 ,\n",
       "        0.76190476, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.9047619 , 0.80952381,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.85714286, 0.80952381,\n",
       "        0.33333333, 0.38095238, 0.19047619, 0.33333333, 0.33333333,\n",
       "        0.33333333, 0.33333333, 0.28571429, 0.33333333, 0.28571429,\n",
       "        0.85714286, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.95238095, 0.9047619 ,\n",
       "        0.85714286, 0.71428571, 0.71428571, 0.95238095, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.9047619 , 0.85714286,\n",
       "        0.9047619 , 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.95238095, 0.9047619 ,\n",
       "        0.33333333, 0.33333333, 0.28571429, 0.38095238, 0.28571429,\n",
       "        0.28571429, 0.38095238, 0.52380952, 0.        , 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.95238095, 0.9047619 ,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.9047619 , 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.95238095, 0.9047619 ,\n",
       "        0.28571429, 0.28571429, 0.0952381 , 0.61904762, 0.28571429,\n",
       "        0.        , 0.14285714, 0.28571429, 0.        , 0.71428571,\n",
       "        0.9047619 , 0.71428571, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.9047619 , 0.9047619 ,\n",
       "        0.95238095, 0.71428571, 0.95238095, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.9047619 , 0.85714286,\n",
       "        0.76190476, 0.76190476, 0.71428571, 0.71428571, 0.71428571,\n",
       "        0.71428571, 0.71428571, 0.71428571, 0.95238095, 0.95238095,\n",
       "        0.28571429, 0.38095238, 0.38095238, 0.38095238, 0.38095238,\n",
       "        0.38095238, 0.42857143, 0.33333333, 0.52380952, 0.        ]),\n",
       " 'mean_test_score': array([0.65714286, 0.62380952, 0.7       , 0.74761905, 0.77142857,\n",
       "        0.74285714, 0.76666667, 0.71904762, 0.73809524, 0.7047619 ,\n",
       "        0.6952381 , 0.74285714, 0.67142857, 0.68571429, 0.71904762,\n",
       "        0.69047619, 0.79047619, 0.76666667, 0.78095238, 0.76190476,\n",
       "        0.71428571, 0.7       , 0.76190476, 0.66666667, 0.72857143,\n",
       "        0.73809524, 0.84285714, 0.85238095, 0.75714286, 0.74285714,\n",
       "        0.32857143, 0.3047619 , 0.34761905, 0.3047619 , 0.30952381,\n",
       "        0.32380952, 0.26666667, 0.31904762, 0.36190476, 0.37619048,\n",
       "        0.76666667, 0.68571429, 0.81428571, 0.70952381, 0.76190476,\n",
       "        0.72380952, 0.79047619, 0.7047619 , 0.8047619 , 0.6952381 ,\n",
       "        0.77142857, 0.69047619, 0.74761905, 0.65238095, 0.79047619,\n",
       "        0.7047619 , 0.82380952, 0.70952381, 0.75714286, 0.77142857,\n",
       "        0.64285714, 0.60952381, 0.77619048, 0.69047619, 0.78095238,\n",
       "        0.67142857, 0.81904762, 0.72857143, 0.78095238, 0.72857143,\n",
       "        0.31904762, 0.33333333, 0.27619048, 0.43333333, 0.3047619 ,\n",
       "        0.28095238, 0.32857143, 0.3047619 , 0.34285714, 0.3047619 ,\n",
       "        0.74761905, 0.58571429, 0.7952381 , 0.72857143, 0.81904762,\n",
       "        0.73809524, 0.84761905, 0.61904762, 0.84761905, 0.69047619,\n",
       "        0.8047619 , 0.66190476, 0.75714286, 0.71904762, 0.7952381 ,\n",
       "        0.72857143, 0.78571429, 0.78571429, 0.8047619 , 0.75238095,\n",
       "        0.77142857, 0.62380952, 0.72857143, 0.7       , 0.79047619,\n",
       "        0.72380952, 0.81904762, 0.7952381 , 0.86190476, 0.72380952,\n",
       "        0.33809524, 0.3       , 0.33809524, 0.32857143, 0.29047619,\n",
       "        0.3       , 0.31904762, 0.34285714, 0.28571429, 0.34285714,\n",
       "        0.76190476, 0.69047619, 0.81428571, 0.72380952, 0.83809524,\n",
       "        0.7047619 , 0.83809524, 0.73809524, 0.9047619 , 0.78095238,\n",
       "        0.79047619, 0.59047619, 0.75238095, 0.71904762, 0.8       ,\n",
       "        0.6       , 0.81428571, 0.77142857, 0.83809524, 0.75238095,\n",
       "        0.74285714, 0.65714286, 0.75238095, 0.69047619, 0.78571429,\n",
       "        0.72857143, 0.86666667, 0.76666667, 0.82380952, 0.7952381 ,\n",
       "        0.33333333, 0.28571429, 0.28571429, 0.45238095, 0.41428571,\n",
       "        0.32380952, 0.27142857, 0.37619048, 0.36190476, 0.39047619,\n",
       "        0.8       , 0.63809524, 0.77619048, 0.69047619, 0.82857143,\n",
       "        0.71428571, 0.87142857, 0.75714286, 0.86190476, 0.77619048,\n",
       "        0.79047619, 0.69047619, 0.79047619, 0.66190476, 0.86666667,\n",
       "        0.70952381, 0.83333333, 0.76666667, 0.85714286, 0.75238095,\n",
       "        0.71428571, 0.72857143, 0.83333333, 0.69047619, 0.83333333,\n",
       "        0.7952381 , 0.85714286, 0.81428571, 0.89047619, 0.73809524,\n",
       "        0.32857143, 0.33809524, 0.4       , 0.35714286, 0.33333333,\n",
       "        0.31428571, 0.30952381, 0.28095238, 0.4047619 , 0.1952381 ]),\n",
       " 'std_test_score': array([0.18170271, 0.1387505 , 0.16639434, 0.14761905, 0.08728716,\n",
       "        0.08024905, 0.13710648, 0.16557465, 0.11318918, 0.08984744,\n",
       "        0.16929894, 0.08302665, 0.16693855, 0.13997084, 0.08637313,\n",
       "        0.09583148, 0.16106223, 0.17096498, 0.11895234, 0.12046772,\n",
       "        0.1635768 , 0.15215757, 0.19401475, 0.19047619, 0.12242819,\n",
       "        0.07142857, 0.1205618 , 0.10952381, 0.13032316, 0.16659863,\n",
       "        0.04492372, 0.04364358, 0.22136456, 0.10900498, 0.1070105 ,\n",
       "        0.05553288, 0.13834132, 0.11478067, 0.12634761, 0.19914784,\n",
       "        0.13710648, 0.14630754, 0.16281258, 0.15569317, 0.09035079,\n",
       "        0.12562768, 0.11507663, 0.21060328, 0.11942796, 0.14474937,\n",
       "        0.16329932, 0.15685399, 0.19290123, 0.16639434, 0.11106575,\n",
       "        0.11428571, 0.12242819, 0.16419943, 0.05812646, 0.17791944,\n",
       "        0.09343532, 0.16329932, 0.1551095 , 0.14166166, 0.11507663,\n",
       "        0.10743347, 0.10816968, 0.16502594, 0.17586843, 0.18571429,\n",
       "        0.03719167, 0.04259177, 0.16049809, 0.1387505 , 0.06459362,\n",
       "        0.11358915, 0.0720607 , 0.1047619 , 0.06666667, 0.0315869 ,\n",
       "        0.1086925 , 0.1636461 , 0.15065992, 0.17043362, 0.11625291,\n",
       "        0.06116777, 0.11428571, 0.20865621, 0.12562768, 0.16666667,\n",
       "        0.16281258, 0.20586635, 0.18620205, 0.16693855, 0.12242819,\n",
       "        0.08261596, 0.0803902 , 0.163923  , 0.1213118 , 0.12196427,\n",
       "        0.11024607, 0.16963346, 0.12607812, 0.1551095 , 0.1208436 ,\n",
       "        0.16605329, 0.09233676, 0.17307411, 0.10952381, 0.1576471 ,\n",
       "        0.06884206, 0.10443672, 0.20805764, 0.14669449, 0.10312575,\n",
       "        0.07982407, 0.1127878 , 0.06666667, 0.1635768 , 0.16329932,\n",
       "        0.13801311, 0.19313619, 0.13710648, 0.16741329, 0.14784928,\n",
       "        0.11024607, 0.13997084, 0.14325342, 0.11468185, 0.14158161,\n",
       "        0.15532863, 0.1771531 , 0.19726014, 0.17228621, 0.12562768,\n",
       "        0.16246402, 0.10952381, 0.15907898, 0.10257457, 0.1038925 ,\n",
       "        0.11507663, 0.20734801, 0.1038925 , 0.12279807, 0.08584646,\n",
       "        0.18201443, 0.10816968, 0.08895972, 0.08793422, 0.09047619,\n",
       "        0.04259177, 0.14599724, 0.17561037, 0.14482768, 0.13809524,\n",
       "        0.14412139, 0.1086925 , 0.11358915, 0.19307748, 0.11818737,\n",
       "        0.14412139, 0.14784928, 0.12426656, 0.14166166, 0.11895234,\n",
       "        0.04761905, 0.10224243, 0.15857929, 0.10090295, 0.11478067,\n",
       "        0.13162167, 0.14638501, 0.18832114, 0.1837503 , 0.11228406,\n",
       "        0.14514048, 0.11712737, 0.12857143, 0.08780519, 0.14412139,\n",
       "        0.13468701, 0.05654449, 0.14166166, 0.14638501, 0.10045249,\n",
       "        0.1205618 , 0.15356681, 0.20141225, 0.11673953, 0.18101503,\n",
       "        0.16141382, 0.04492372, 0.16246402, 0.163923  , 0.03011693,\n",
       "        0.11106575, 0.17202278, 0.16963346, 0.12821821, 0.16963346]),\n",
       " 'rank_test_score': array([139, 144, 118,  80,  60,  83,  65, 106,  87, 114, 122,  83, 134,\n",
       "        132, 104, 124,  45,  62,  51,  67, 109, 118,  67, 136,  94,  87,\n",
       "         13,  10,  71,  83, 172, 184, 162, 184, 182, 177, 199, 178, 159,\n",
       "        157,  65, 132,  26, 111,  67, 100,  40, 116,  30, 121,  57, 124,\n",
       "         80, 141,  40, 114,  21, 111,  71,  60, 142, 147,  55, 124,  50,\n",
       "        134,  23,  94,  51,  94, 179, 169, 197, 152, 184, 195, 172, 188,\n",
       "        163, 184,  82, 150,  35,  92,  23,  87,  11, 146,  11, 124,  30,\n",
       "        138,  71, 104,  35,  94,  48,  48,  30,  76,  57, 145,  94, 118,\n",
       "         40, 101,  23,  35,   6, 101, 166, 189, 166, 172, 191, 189, 179,\n",
       "        163, 192, 163,  67, 124,  26, 101,  14, 116,  14,  91,   1,  51,\n",
       "         40, 149,  75, 106,  33, 148,  26,  57,  14,  76,  83, 139,  76,\n",
       "        124,  47,  92,   4,  62,  21,  35, 169, 192, 192, 151, 153, 176,\n",
       "        198, 158, 159, 156,  33, 143,  54, 124,  20, 108,   3,  74,   6,\n",
       "         55,  45, 124,  40, 137,   4, 111,  18,  62,   8,  76, 109,  94,\n",
       "         17, 123,  18,  35,   8,  26,   2,  87, 172, 168, 155, 161, 171,\n",
       "        181, 182, 195, 154, 200])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Если бы мы работали с большим набором данных, где было бы много признаков и много объектов, каждая модель обучалась бы значительное количество времени и мы бы хотели действительно подобрать много параметров**. Тогда этот процесс занял бы существенное время, и с точки зрения вычислительной эффективности, возможно, нам было бы не так выгодно использовать полный перебор по сетке. Какие есть альтернативы? **Можно использовать случайный поиск по сетке**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.RandomizedSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_grid_cv = model_selection.RandomizedSearchCV(estimator=classifier,\n",
    "                                                        param_distributions=parameters_grid,\n",
    "                                                        scoring = 'accuracy', cv = cv, n_iter = 20, \n",
    "                                                        random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 470 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=0.2,\n",
       "            train_size=None),\n",
       "                   estimator=SGDClassifier(random_state=0), n_iter=20,\n",
       "                   param_distributions={'alpha': array([0.0001  , 0.000325, 0.00055 , 0.000775, 0.001   ]),\n",
       "                                        'loss': ['hinge', 'log',\n",
       "                                                 'squared_hinge',\n",
       "                                                 'squared_loss'],\n",
       "                                        'max_iter': array([5, 6, 7, 8, 9]),\n",
       "                                        'penalty': ['l1', 'l2']},\n",
       "                   random_state=0, scoring='accuracy')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "randomized_grid_cv.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666666666666666\n",
      "{'penalty': 'l1', 'max_iter': 8, 'loss': 'squared_hinge', 'alpha': 0.0007750000000000001}\n"
     ]
    }
   ],
   "source": [
    "print(randomized_grid_cv.best_score_)\n",
    "print(randomized_grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-30 21:10:58\n",
      "Control sum: 942\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def control_sum(str):\n",
    "    return sum(map(ord, list(str)))\n",
    "\n",
    "\n",
    "def check(reply):\n",
    "    def _is_number(str):\n",
    "        try:\n",
    "            int(str)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    if \"Control sum:\" not in reply:\n",
    "        return False\n",
    "    parts = reply.split(\"Control sum:\")\n",
    "    received_current_time = parts[0].strip()\n",
    "    received_control_sum = parts[1].strip()\n",
    "    if not _is_number(received_control_sum):\n",
    "        return False\n",
    "    else:\n",
    "        received_control_sum = int(received_control_sum)\n",
    "    expected_control_sum = control_sum(received_current_time)\n",
    "    return expected_control_sum == received_control_sum\n",
    "\n",
    "\n",
    "current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(current_time)\n",
    "print(\"Control sum: \" + str(control_sum(current_time)))\n",
    "\n",
    "#print check(current_time + '\\n' + \"Control sum: \" + str(control_sum(current_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Содержание",
   "title_sidebar": "Содержание",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
